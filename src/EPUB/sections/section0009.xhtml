<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type"/>
    <link href="../styles/stylesheet.css" rel="stylesheet" type="text/css"/>
    <title/>
  </head>
  <body xmlns:epub="http://www.idpf.org/2007/ops" class="body0">
  <p class="para14">
      <span class="span5">L’arnaque des algorithmes d’aide à la prise de décision</span>
    </p>
    <p class="para23">
      <span class="span6">Bastien Le Que</span><span class="span6">rr</span><span class="span6">ec,</span> <span class="span29">doctorant</span> <span class="span6">en droit public</span>
    </p>
    <p class="para23">
       
    </p>
    <p class="para3">
       
    </p>
    <p class="para3">
      <span class="span2">L’administration, au sens public du terme, prend tous les jours un certain nombre de
      décisions</span><span class="span2"> :</span> <span class="span2">lorsqu’elle accorde une allocation, lorsqu’elle
      retire un permis de conduire, lorsqu’elle accepte un·e étudiant·e dans une formation supérieure, lorsqu’elle est
      chargée d’appliquer une loi, etc. Décider est le quotidien de l’administration et administrer, nous dit le
      dictionnaire Larousse, signifie</span> <span class="span2">« </span><span class="span6">diriger, gérer des
      affaires publiques ou privées</span><span class="span6"> »</span><span class="span2">. La Constitution nous
      prévient également que</span> <span class="span2">« </span><span class="span6">le Gouvernement détermine et
      conduit la politique de la nation</span><span class="span6"> »</span> <span class="span2">et</span> <span class="span2">« </span><span class="span6">dispose de l’administration</span><span class="span6"> »</span> <span class="span2">(article 20). Le rôle de l’administration dans la conduite des affaires publiques est donc fondamental. À
      cette fin, son pouvoir de décision l’est tout autant.</span>
    </p>
    <p class="para3">
      <span class="span2">Décider est donc une fonction intrinsèque à l’administration, mais décider n’est pas toujours
      le fruit d’un processus entièrement humain. L’administration s’est toujours dotée de règles, de documents, de
      cadres, pour décider, quand bien même aucune obligation ne le lui imposerait</span><span class="span2"> :</span>
      <span class="span2">le pouvoir discrétionnaire dont jouit très souvent l’administration est limité par
      elle-même.</span>
    </p>
    <p class="para3">
      <span class="span2">De plus, l’arrivée ces derniers temps d’un nouvel outil pour l’administration, l’algorithme,
      change radicalement la manière dont on peut concevoir la décision administrative. Skip Machine lave plus blanc
      que blanc</span><span class="span2"> ;</span> <span class="span2">l’algorithme décide plus efficacement que
      l’humain. Il en résulte un miracle</span><span class="span2"> :</span> <span class="span2">la décision
      administrative algorithmique. Le législateur est intervenu, pour répondre à un certain nombre de craintes. Mais
      la pratique administrative tend à contourner ces protections grâce à un nouvel outil, l’algorithme d’aide à la
      prise de décision.</span>
    </p>
    <p class="para3">
      <span class="span2">Avant toute chose, il est nécessaire de s’entendre sur la notion de décision et celle
      d’algorithme. Nous entendons ici un algorithme (ou son équivalent juridique de</span> <span class="span2">« </span><span class="span2">traitement algorithmique</span><span class="span2"> »</span><span class="span2">) comme une suite d’opérations mathématiques avec en entrée plusieurs paramètres et en sortie un résultat
      unique (mais pas forcément reproductible, comme nous le verrons plus tard). Un algorithme n’a donc pas à être
      compliqué</span><span class="span2"> :</span> <span class="span2">un rapport sénatorial a ainsi pu comparer une
      recette de cuisine à un algorithme</span><sup id="calledF1"><a epub:type="noteref" href="#dataF1">50</a></sup><span class="span2">. Il ne s’agit pas forcément non plus d’un programme informatique ou de
      lignes de codes exécutables</span><span class="span2"> :</span> <span class="span2">un algorithme peut également
      être une série de formules dans une feuille de calcul</span><sup id="calledF2"><a epub:type="noteref" href="#dataF2">51</a></sup><span class="span2">.</span>
    </p>
    <p class="para3">
      <span class="span2">On classera toutefois les algorithmes en deux catégories</span><span class="span2"> :</span>
      <span class="span2">les algorithmes auto-apprenants et les autres. Les premiers (on parlera également
      d’</span><span class="span2">« </span><span class="span2">intelligence artificielle</span><span class="span2"> »</span><span class="span2">, de</span> <span class="span2">« </span><span class="span6">machine
      learning</span><span class="span6"> »</span> <span class="span2">ou de</span> <span class="span2">« </span><span class="span6">deep learning</span><span class="span6"> »</span><span class="span2">)
      fonctionnent avec une phase d’apprentissage préalable. Dans un premier temps, l’algorithme auto-apprenant
      s’entraîne sur un jeu de données dont le résultat attendu est connu (par exemple</span><span class="span2"> :</span> <span class="span2">« </span><span class="span6">cette image est un chaton</span><span class="span6"> »</span> <span class="span2">ou</span> <span class="span2">« </span><span class="span6">cette image
      n’est pas un chaton</span><span class="span6"> »</span><span class="span2">) et s’adapte en comparant ses
      résultats à ceux attendus. Une fois cette phase terminée, il est utilisé alors que le résultat</span>
      <span class="span2">attendu n’est pas connu (dans notre exemple, il sera censé distinguer les images de chatons
      des autres). Le résultat d’un algorithme auto-apprenant n’est pas reproductible puisqu’il dépendra de la phase
      d’apprentissage et de la qualité du jeu de données initial. Les autres algorithmes, ceux qui ne sont pas
      auto-apprenants, ont un résultat reproductible puisqu’il ne repose pas sur une phase préalable
      d’apprentissage.</span>
    </p>
    <p class="para3">
      <span class="span2">Une décision administrative, quant à elle, est un acte administratif (au sens de document
      émanant d’une administration</span><sup id="calledF3"><a epub:type="noteref" href="#dataF3">52</a></sup><span class="span2">) décisoire. Lorsque l’administration constate quelque chose (ce que
      font beaucoup d’autorités de régulation, par exemple), elle ne fait pas de choix et son acte n’est donc pas une
      décision.</span>
    </p>
    <p class="para3">
      <span class="span2">Enfin, nous entendrons une décision administrative algorithmique comme un type de décision
      administrative dans laquelle un algorithme a été utilisé durant le processus de prise de décision. L’algorithme
      n’a pas à être le seul fondement à la décision pour que celle-ci soit qualifiable de décision administrative
      algorithmique. Il faut distinguer la décision algorithmique de l’algorithme d’aide à la prise de décision : le
      premier fonde la décision, le deuxième est utilisé en amont de la décision et ne la fonde alors pas.</span>
    </p>
    <p class="para3">
      <span class="span2">Arrêtons-nous tout d’abord sur ce qui motive l’administration à utiliser des algorithmes (I).
      Voyons ensuite les barrières prévues par le droit pour les décision</span><span class="span2">s</span>
      <span class="span2">algorithmique</span><span class="span2">s</span> <span class="span2">(II) et comment
      l’administration les contourne grâce aux algorithmes d’aide à la prise de décision (III). Enfin, étudions les
      conséquences de ces algorithmes d’aide à la prise de décision sur nos droits fondamentaux (IV).</span>
    </p>
    <p class="para4">
      <span class="span1">I. Un recours aux décisions algorithmiques de plus en plus important</span>
    </p>
    <p class="para3">
      <span class="span2">Il est difficile – pour ne pas dire impossible – de systématiser l’utilisation d’un
      algorithme. L’administration n’est jamais tenue d’y avoir recours, ce n’est qu’une faculté (explicitement admise
      par la loi depuis 2016</span><sup id="calledF4"><a epub:type="noteref" href="#dataF4">53</a></sup><span class="span2">).</span>
    </p>
    <p class="para3">
      <span class="span2">En tout état de cause, lorsqu’elle y a recours, cela peut être pour atteindre deux objectifs.
      Premièrement, il peut s’agir d’une situation dans laquelle l’administration doit prendre beaucoup de décisions
      dans un laps de temps restreint. Elle veut alors accélérer la prise de décision. Dans ce cas, l’algorithme est
      souvent très simple et il s’agit principalement de décisions administratives individuelles (c’est-à-dire dont le
      destinataire est une personne nommée ou un groupe de personnes individualisées). Le cas des algorithmes locaux de
      Parcou</span><span class="span2">r</span><span class="span2">sup illustre parfaitement cette situation : les
      universités doivent, en quelques semaines, classer des milliers de candidatures en attribuant à chaque
      candidat</span><span class="span13">·e</span> <span class="span2">un rang précis</span><span class="span2"> ;</span> <span class="span2">les algorithmes locaux de Parcoursup appliquent à l’ensemble des
      candidat</span><span class="span13">·e</span><span class="span13">s</span> <span class="span2">une même règle
      pour donner</span> <span class="span6">in fine</span> <span class="span2">un rang à chaque candidature. Les
      algorithmes locaux de Parcoursup sont une simple feuille de calcul sur laquelle les commissions de classement ont
      donné une importance plus ou moins grande à certains critères académiques parmi ceux transmis par la plateforme
      aux universités (notes, appréciations, lycée d’origine, etc.</span><sup id="calledF5"><a epub:type="noteref" href="#dataF5">54</a></sup><span class="span2">).</span>
    </p>
    <p class="para3">
      <span class="span2">Deuxièmement, il peut s’agir de détecter ce que l’on estime impossible à trouver par une
      analyse humaine</span><span class="span2"> :</span> <span class="span2">il s’agit de la recherche de signaux
      faibles. Dans cette situation, le recours aux algorithmes auto-apprenants est le plus souvent nécessaire. Par
      exemple, la surveillance algorithmique des réseaux de communication (parfois appelée</span> <span class="span2">« </span><span class="span2">boîtes noires</span><span class="span2"> »</span><span class="span2">)
      permises depuis la loi renseignement de 2015</span><sup id="calledF6"><a epub:type="noteref" href="#dataF6">55</a></sup> <span class="span2">repose sur des algorithmes auto-apprenants dont le but est de détecter
      des risques à caractère terroriste qu’on estime indétectable par un analyste du renseignement.</span>
    </p>
    <p class="para4">
      <span class="span1">II. L’algorithme comme fondement de la décision administrative</span><span class="span1"> :</span> <span class="span1">une protection théorique contre les abus de la décision administrative
      algorithmique</span>
    </p>
    <p class="para3">
      <span class="span2">Ce panorama étant posé, une peur peut légitimement naître</span><span class="span2"> :</span>
      <span class="span2">comment être certain</span><span class="span13">·e</span> <span class="span2">qu’un
      algorithme a pris la bonne décision</span><span class="span2"> ?</span> <span class="span2">Il est
      intellectuellement plus facile de contester une décision prise par un</span><span class="span13">·e</span>
      <span class="span2">humain</span><span class="span13">·e</span> <span class="span2">que de contester une décision
      prise par une machine dont l’aléatoire est réputé neutralisé.</span>
    </p>
    <p class="para3">
      <span class="span2">Le droit offre un certain nombre de mesures protectrices – bien qu’insuffisantes en pratique
      – lorsqu’un traitement algorithmique a été le fondement d’une décision. Autrement dit, lorsque l’administration,
      pour prendre sa décision, se base sur les résultats d’un algorithme, le droit pose des limites. L’article L.
      311-3-1 du code des relations entre le public et l’administration énonce ainsi le droit de se faire communiquer
      les</span> <span class="span2">« </span><span class="span6">règles définissant ce traitement ainsi que les
      principales caractéristiques de sa mise en œuvre</span><span class="span6"> »</span><sup id="calledF7"><a epub:type="noteref" href="#dataF7">56</a></sup> <span class="span2">dans le cas d’une décision
      administrative individuelle prise sur le fondement d’un traitement algorithmique. Ainsi, lorsque l’administration
      prend une décision individuelle à l’aide d’un algorithme, un droit à se faire communiquer certaines informations
      sur l’algorithme naît au bénéfice du destinataire de la décision. Une forme de transparence est ainsi posée et
      d’elle découle une forme de contrôle sur la qualité de l’algorithme, donc de la décision qui en découle.</span>
    </p>
    <p class="para3">
      <span class="span2">Le Conseil constitutionnel est également venu poser un garde-fou important à l’usage
      d’algorithmes dans les décisions administratives. Il a ainsi précisé que l’administration doit pouvoir expliquer
      et reproduire ses résultats</span><span class="span2"> :</span> <span class="span2">les algorithmes
      auto-apprenants sont donc théoriquement exclus de la prise de décision.</span><sup id="calledF8"><a epub:type="noteref" href="#dataF8">57</a></sup>
    </p>
    <p class="para3">
      <span class="span2">Enfin, précisons également que le code source des algorithmes sont des documents
      administratifs au sens de la loi.</span><sup id="calledF9"><a epub:type="noteref" href="#dataF9">58</a></sup>
      <span class="span2">À ce titre, il est possible, en dehors des cas de décisions administratives individuelles, de
      se faire communiquer de tels documents.</span><sup id="calledF10"><a epub:type="noteref" href="#dataF10">59</a></sup>
    </p>
    <p class="para4">
      <span class="span1">III. L’algorithme comme simple aide</span><span class="span1"> :</span> <span class="span1">l’absence de toute garantie contre les algorithmes d’aide à la prise de décision</span>
    </p>
    <p class="para3">
      <span class="span2">La pratique administrative tend à exclure de plus en plus les algorithmes de la prise de
      décision. Si</span> <span class="span2">l’algorithme n’est plus considéré comme ayant fondé une décision, alors
      les limites posées (notamment l’interdiction de recourir à des algorithmes auto-apprenants donc aux résultats non
      reproductibles) n’existent plus du tout.</span>
    </p>
    <p class="para3">
      <span class="span2">C’est ce qu’il se passe avec le recours des algorithmes dits</span> <span class="span2">« </span><span class="span2">d’aide à la prise de décision</span><span class="span2"> »</span><span class="span2">. Ces algorithmes sont utilisés bien en amont de la prise de
      décision</span><span class="span2"> :</span> <span class="span2">il s’agit de guider l’administration dans son
      action au quotidien, avant qu’une décision ne soit prise. On retrouve de tels algorithmes par exemple dans la
      lutte contre la fraude fiscale et douanière, dans la lutte contre le terrorisme, la police prédictive,
      etc.</span>
    </p>
    <p class="para3">
      <span class="span2">Ces algorithmes d’aide à la prise de décision fonctionnent selon une même logique : une
      alerte ou une recommandation est levée par l’algorithme. Un·e agent de l’administration reçoit cette alerte ou
      cette recommandation, puis décide de prendre ou non une décision. Le fondement de la décision n’est donc plus
      l’algorithme, qui a seulement invité l’agent à s’intéresser à une situation particulière. L’algorithme d’aide à
      la prise de décision n’est plus au fondement de la décision, il est détaché.</span>
    </p>
    <p class="para3">
      <span class="span2">Ainsi, l’algorithme</span> <span class="span6">Paved</span> <span class="span2">(« plateforme
      d’analyse et de visualisation évolutive de la délinquance ») de la gendarmerie ne fait qu’afficher les zones à
      risques</span><span class="span2"> :</span> <span class="span2">il ne détermine pas les zones dans lesquelles les
      patrouilles seront positionnées. L’agent choisira seul·e de placer ses patrouilles dans les zones à risque ou
      non. Il en va de même pour les boites noires utilisées par les services de renseignement (cf.</span> <span class="span6">supra</span> <span class="span2">pour leur présentation)</span><span class="span2"> :</span> <span class="span2">elles ne lèvent qu’une alerte sur une potentielle menace, libre ensuite à l’analyste du renseignement de
      procéder ou non à une surveillance plus ciblée. Ce même fonctionnement vaut également pour les algorithmes de
      Bercy chargés de détecter les potentielles fraudes fiscales</span><span class="span2"> :</span> <span class="span2">les agents du fisc sont toujours libres de procéder ou non au contrôle fiscal.</span>
    </p>
    <p class="para3">
      <span class="span2">Ces exemples sont réels et l’hypocrisie est flagrante. Si l’administration demande à un
      algorithme de l’aider, soit en augmentant le nombre de situations traitées, soit en détectant ce
      qu’un</span><span class="span13">·e</span> <span class="span2">humain</span><span class="span13">·e</span>
      <span class="span2">ne pourrait pas voir, pourquoi ne pas suivre ses recommandations</span><span class="span2"> ?</span> <span class="span2">On pourrait répondre que lorsqu’une alerte ou une recommandation est émise,
      l’agent pourrait refaire le traitement sur la situation spécifique afin de vérifier la qualité du résultat de
      l’algorithme. Cependant, premièrement, aucune obligation n’impose à l’administration une telle vérification.
      Deuxièmement, ce serait omettre les résultats négatifs qui impliquent une forme de validation de la situation par
      l’algorithme. Troisièmement, ce serait réduire drastiquement les gains de productivité demandés à ces algorithmes
      dans certaines situations. Quatrièmement, enfin, certains cas ne se prêtent tout simplement pas à une telle
      vérification, notamment lorsqu’il est demandé à l’algorithme de repérer les signaux faibles.</span>
    </p>
    <p class="para3">
      <span class="span2">En réalité, lorsqu’une alerte ou une recommandation est levée par un algorithme d’aide à la
      prise de décision, l’administration se bornera à vérifier les erreurs grossières pour les cas positifs. Elle ne
      vérifiera jamais les résultats négatifs. L’humain</span><span class="span13">·e</span> <span class="span2">chargé</span><span class="span13">·e</span> <span class="span2">de réceptionner les alertes ou
      recommandations n’aura qu’un rôle de vérification</span> <span class="span6">a minima</span><span class="span2">,
      au risque, autrement, d’aller à l’encontre des gains de production demandés. Le doute sera donc nécessairement au
      détriment de l’administré·e. Éventuellement, il peut être demandé à l’agent d’opérer un classement pour ne
      prendre en considération qu’un nombre limité de cas. On peut penser qu’un tel choix est fait dans les domaines où
      un contingentement existe en fait ou en droit (nombre limité de gendarmes mobilisables sur le terrain, quota de
      mises sous surveillance, etc.). Mais rien n’indique que ce choix ne soit pas dû au hasard</span> <span class="span2">(notamment lorsque l’humain</span><span class="span13">·e</span> <span class="span2">n’est pas
      censé</span><span class="span13">·e</span> <span class="span2">pouvoir apprécier la situation).</span>
    </p>
    <p class="para4">
      <span class="span1">IV. Des conséquences négatives concrètes sur les droits fondamentaux</span>
    </p>
    <p class="para3">
      <span class="span2">Le résultat de tout cela est assez décevant. D’une part, l’usage même de ces algorithmes
      d’aide à la prise de décision implique un droit à un recours effectif limité. Dès 2016</span><sup id="calledF11"><a epub:type="noteref" href="#dataF11">60</a></sup><span class="span2">, la Cour suprême du Wisconsin
      affirmait qu’il n’est pas possible de contester le résultat d’un algorithme d’aide à la prise de décision puisque
      seul l’humain</span><span class="span13">·e</span> <span class="span2">a pris la décision</span><span class="span2"> :</span> <span class="span2">la seule décision attaquable devant un juge est celle prise par
      un</span><span class="span13">·e</span> <span class="span2">humain</span><span class="span13">·e</span><span class="span2">, et elle seule, même si un algorithme a aidé à cette prise de décision. Il
      n’existe donc pas de recours direct contre ces algorithmes puisqu’ils sont passés par le truchement
      d’un</span><span class="span13">·e</span> <span class="span2">humain</span><span class="span13">·e</span>
      <span class="span2">avant la prise de décision en tant que telle.</span>
    </p>
    <p class="para3">
      <span class="span2">Mais, même dans le cas des décisions administratives algorithmiques – c’est-à-dire celles
      dont le fondement est un algorithme, contrairement au cas des algorithmes d’aide à la prise de décision –, les
      droits fondamentaux sont limités. Dans ces situation</span><span class="span2">s</span><span class="span2">, on
      se heurtera au pouvoir discrétionnaire de l’administration</span><span class="span2"> :</span> <span class="span2">l’administration, très souvent, a une large possibilité d’action et le rôle du juge se limite à vérifier
      l’absence d’</span><span class="span2">« </span><span class="span2">erreur manifeste
      d’appréciation</span><span class="span2"> »</span><span class="span2">, c’est-à-dire l’absence d’erreur
      grossière. Une décision administrative algorithmique ne sera qu’une décision dans laquelle l’administration a
      voulu, de son chef, limiter son aléa. Mais la manière de le limiter, les paramétrages de l’algorithme, restent un
      choix qui n’est pas vraiment contestable. La transparence (lorsqu’elle est applicable) permettra à l’administré·e
      de vérifier ces erreurs grossières (on peut par exemple penser aux cas de discriminations), mais le doute se fera
      toujours au bénéfice de l’administration.</span>
    </p>
    <p class="para3">
      <span class="span2">D’autre part, l’usage de tels algorithmes va de pair avec une augmentation du nombre de
      données traitées. Pour utiliser des algorithmes, encore faut-il avoir des informations pour les nourrir.
      L’administration est donc incitée à collecter et traiter de plus en plus de données. La récente volonté de Bercy
      de récolter les données publiques des réseaux sociaux n’est que le dernier exemple d’une liste très longue. Avec
      cette collecte, ce sont le droit à la vie privée et familiale ou encore le droit à la liberté d’expression et
      d’information qui se retrouvent limités.</span>
    </p>
    <p class="para3">
      <span class="span37">Le résultat n’est pas réjouissant. L’administration se sert d’algorithmes, mais parfois
      tellement en amont dans son travail qu’il</span><span class="span37">s</span> <span class="span37">ne sont pas
      considérés comme ayant fondé la décision administrative, sapant au passage les garanties posées par le droit. Un
      problème de taille se pose</span><span class="span37"> :</span> <span class="span37">la notion de décision
      administrative, telle qu’elle est conçue aujourd’hui, a-t-elle encore une légitimité à l’heure des algorithmes ?
      Doit-elle évoluer pour réintégrer dans son champ les algorithmes d’aide à la prise de décision ?</span>
    </p>
    <aside epub:type="footnote" id="dataF1">
      <p class="para15">
        <span class="span9"><sup><a href="#calledF1">50</a></sup> </span><span class="span9">Sophie Joissains, Rapport
        n° 350 (2017-2018) fait au nom de la commission des lois sur le projet de loi relatif à la protection des
        données personnelles, 14 mars 2018.</span> <a href="https://www.senat.fr/rap/l17-350/l17-350.html"><span class="span18">https://www.senat.fr/rap/l17-350/l17-350.html</span></a>
      </p>
    </aside><aside epub:type="footnote" id="dataF2">
      <p class="para32">
        <span class="span9"><sup><a href="#calledF2">51</a></sup> </span><span class="span9">Les algorithmes locaux de
        Parcoursup (ceux utilisés par les commissions de classement des vœux de chaque université) ne sont d’ailleurs
        qu’une feuille de calcul dont les pondérations sont laissées à l’appréciation de chaque commission.</span>
      </p>
    </aside><aside epub:type="footnote" id="dataF3">
      <p class="para15">
        <span class="span9"><sup><a href="#calledF3">52</a></sup> </span><span class="span9">Sans entrer dans les
        débats de la doctrine administrativiste autour la notion d’acte administratif, notons simplement que cette
        définition n’est pas partagée pas tou·tes les juristes.</span>
      </p>
    </aside><aside epub:type="footnote" id="dataF4">
      <p class="para15">
        <span class="span9"><sup><a href="#calledF4">53</a></sup> </span><span class="span9">Loi n° 2016-1321 du 7
        octobre 2016 pour une République numérique, article 4, créant l’article L. 311-3-1 du code des relations entre
        le public et l’administration sur les décisions administratives individuelles prises sur le fondement d’un
        traitement algorithmique.</span>
      </p>
    </aside><aside epub:type="footnote" id="dataF5">
      <p class="para32">
        <span class="span9"><sup><a href="#calledF5">54</a></sup> </span><span class="span9">Notons déjà d’emblée que
        les appréciations ne peuvent pas, par une simple feuille de calcul, être évaluées : elles sont donc
        nécessairement mises de côté par l’algorithme et les commissions de classement ne s’en serviront alors que
        pour</span> <span class="span9">dé</span><span class="span9">partager deux éventuel·les candidat·es avec
        exactement le même rang.</span>
      </p>
    </aside><aside epub:type="footnote" id="dataF6">
      <p class="para15">
        <span class="span9"><sup><a href="#calledF6">55</a></sup> </span><span class="span9">Loi n° 2015-912 du 24
        juillet 2015 relative au renseignement, article 15, créant l’article L. 851-2 du code de la sécurité
        intérieure.</span>
      </p>
    </aside><aside epub:type="footnote" id="dataF7">
      <p class="para15">
        <span class="span9"><sup><a href="#calledF7">56</a></sup> </span><span class="span9">Ce qui, selon l’article R.
        311-3-1-2 du même code, englobe, notam</span><span class="span61">ment,</span> <span class="span61">« </span><span class="span61">les paramètres de traitement et, le cas échéant, leur pondération,
        appliqués à la situation de l’intéressé</span><span class="span61"> »</span> <span class="span61">ainsi
        que</span> <span class="span61">« </span><span class="span61">les opérations effectuées par le
        traitement</span><span class="span61"> »</span><span class="span61">.</span>
      </p>
    </aside><aside epub:type="footnote" id="dataF8">
      <p class="para15">
        <span class="span9"><sup><a href="#calledF8">57</a></sup> </span><span class="span9">Cons. const., 12 juin
        2018,</span> <span class="span10">Loi relative à la protection des données personnelles</span><span class="span9">, n° 2018-765 DC, point 71.</span>
      </p>
    </aside><aside epub:type="footnote" id="dataF9">
      <p class="para15">
        <span class="span9"><sup><a href="#calledF9">58</a></sup> </span><span class="span9">Art. L. 300-2 du code des
        relations entre le public et l’administration.</span>
      </p>
    </aside><aside epub:type="footnote" id="dataF10">
      <p class="para32">
        <span class="span9"><sup><a href="#calledF10">59</a></sup> </span><span class="span9">Art. L. 311-1 du code des
        relations entre le public et l’administration.</span>
      </p>
    </aside><aside epub:type="footnote" id="dataF11">
      <p class="para3">
        <span class="span9"><sup><a href="#calledF11">60</a></sup> </span><span class="span9">Cour suprême du
        Wisconsin,</span> <span class="span10">State vs. Eric L. Loomis</span><span class="span9">, 13 juillet
        2016.</span>
      </p>
    </aside></body>
</html>