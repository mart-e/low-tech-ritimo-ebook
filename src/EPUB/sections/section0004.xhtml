<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <link href="../styles/stylesheet.css" rel="stylesheet" type="text/css" />
    <title></title>
  </head>
  <body class="body0" xmlns:epub="http://www.idpf.org/2007/ops">
    <p class="para13">
      <span class="span5">L’Atelier Paysan&nbsp;: produire des technologies appropriées au service de l’agroécologie
      paysanne</span>
    </p>
    <p class="para3">
      &nbsp;
    </p>
    <p class="para3">
      <span class="span52">Quelques questions à Fabrice Clerc, cogérant de l’Atelier Paysan, une coopérative d’auto
      construction paysanne résolument engagée dans une démarche de réappropriation technique</span> <span class=
      "span52">pour des agroéquipements adaptés à l’agroécologie paysanne.</span>
    </p>
    <p class="para4">
      <span class="span1">Qu’est-ce l’Atelier Paysan&nbsp;? Quelles sont vos activités&nbsp;?</span>
    </p>
    <p class="para3">
      <span class="span53">L’Atelier Paysan</span> <span class="span37">est une coopérative d’intérêt collectif à but
      non lucratif qui accompagne des paysan·nes dans la conception et la fabrication de machines et de bâtiments
      adaptés à une agroécologie paysanne.</span>
    </p>
    <p class="para3">
      <span class="span2">Nous menons plusieurs types d’activités, à commencer par les Tournées de Recensement
      d’Innovations Paysannes (dites TRIPS). Partout en France, nous allons de fermes en fermes recueillir et
      documenter des adaptations, astuces et inventions mises en place par des paysan·nes sur leurs machines et leurs
      bâtiments agricoles.</span>
    </p>
    <p class="para3">
      <span class="span37">Nous accompagnons également des dynamiques de recherche et développement participative.
      À</span> <span class="span37">partir de besoins identifiés par des producteur·rices, les ingénieurs et
      l’architecte de la coopérative produisent avec ces groupes paysans les cahiers de charges, plans et prototypes
      des outils. Après test et validation collective, les plans et tutoriels sont publiés intégralement sous licence
      libre et téléchargeables gratuitement sur le site internet de l’Atelier Paysan où il est également possible de
      retrouver les chroniques des TRIPS réalisées dans les fermes. Nous proposons enfin des formations à
      l’auto-construction pendant lesquelles les paysan·nes apprennent à travailler le bois et métal et fabriquent des
      outils adaptés à leur activité.</span>
    </p>
    <p class="para4">
      <span class="span1">Quel est le rapport de votre coopérative avec les technologies&nbsp;?</span>
    </p>
    <p class="para3">
      <span class="span2">Le projet même de l’Atelier Paysan repose sur une interrogation de la technologie et de son
      usage en agriculture&nbsp;: les agroéquipements aujourd’hui disponibles répondent-ils réellement aux besoins des
      paysan·nes&nbsp;? Favorisent-ils leur autonomie ou, à l’inverse, la restreignent-ils&nbsp;? À quelle agriculture
      sont-ils adaptés&nbsp;? À qui le progrès technique bénéficie-t-il&nbsp;?</span>
    </p>
    <p class="para3">
      <span class="span2">Et malheureusement, les technologies agricoles n’échappent pas au rouleau compresseur de
      l’industrialisation de l’agriculture à l’œuvre depuis plus d’un demi-siècle. Règles de propriété intellectuelle
      et industrielle, normes adaptées à l’agriculture industrielle, prix exorbitants et complexification des outils et
      procédures sont autant d’éléments qui tendent à restreindre les capacités de prise de décision des paysans et
      paysannes en ce qui concerne leur agroéquipement.</span>
    </p>
    <p class="para3">
      <span class="span37">À l’Atelier Paysan, nous partons du principe que les paysan·nes sont assez bien placé·es
      pour répondre de manière pertinente aux défis du développement agricole&nbsp;: les agriculteur·trices innovent
      par eux-mêmes sur leurs fermes. Mieux&nbsp;! En groupe, en réseau ou avec l’appui d’un animateur technique, ils
      et</span> <span class="span37">elles savent élaborer collectivement des réponses adaptées. Nous portons l’idée
      que les choix techniques doivent être faits avec, par et pour les agriculteur·rices, et plus globalement, que la
      technique doit</span> <span class="span16">être investie collectivement pour se mettre au service de celles et
      ceux qui l’utilisent.</span> <span class="span53">Nous mesurons toute</span> <span class="span53">l’importance
      des réseaux socio-techniques de producteur·rices</span><span class="span16">, à la fois dans la production et le
      partage de savoirs.</span> <span class="span37">Cette prise paysanne sur les choix techniques peut alors être un
      vecteur de l’autonomie paysanne.</span>
    </p>
    <p class="para3">
      <span class="span37">Au-delà de</span><span class="span37">s dynamiques de construction sur le terrain, nous
      cherchons également à faire émerger une analyse politique sur la technologie en agriculture et à construire du
      rapport de force sur ces questions. Nous avons ainsi élaboré avec les structures du pôle Inpact</span>
      <span class="span37">(Initiatives Pour une Agriculture Citoyenne et Territoriale) un plaidoyer pour la
      souveraineté technologique des paysan·nes. Nous travaillons par ailleurs en ce moment avec des chercheur·ses en
      sciences sociales autour de la machine agricole pour comprendre et documenter la mécanisation de l’agriculture en
      France depuis 1945.</span>
    </p>
    <p class="para4">
      <span class="span1">Et le low tech, dans tout cela&nbsp;?</span>
    </p>
    <p class="para3">
      <span class="span37">Cette question des low tech fait directement écho aux technologies appropriées que nous
      souhaitons promouvoir et développer. En apprenant à travailler le métal et le bois, les paysan·nes augmentent
      leur capacité à fabriquer et réparer leur matériel et réduisent leur dépendance expert·es extérieur·es à la
      ferme. Ils et elles se dotent d’outils, machines et bâtiments moins chers, appropriés à leurs besoins et
      appropriables. En moyenne, on estime qu’auto-construire ses outils revient à diviser par deux ou trois les
      investissements financiers pour s’équiper en comparaison aux prix du marché (quand les outils existent, car ils
      sont bien souvent peu ou pas adaptés à des exploitations à taille humaine ou conduites en bio). Des outils,
      machines et bâtiments agricoles simples, pratiques et économiques mais aussi «&nbsp;vivants&nbsp;», évoluant au
      gré des améliorations par une communauté de paysan·nes. Nous pensons que les machines et les savoirs paysans
      associés sont des</span> <span class="span53">communs</span><span class="span16">,</span> <span class=
      "span37">librement diffusables et modifiables. D’où la diffusion sous licence libre sur notre site internet des
      plans et tutoriels des machines ainsi que la création d’un forum en ligne, espace d’échanges très fécond entre
      les auto-constructeurs et auto-constructrices.</span>
    </p>
    <p class="para3">
      <span class="span37">Concernant l’aspect environnemental que l’on retrouve aussi dans les low tech, nous
      travaillons sur des outils moins dépendants des énergies fossiles, notamment le pétrole, avec du matériel pour la
      traction animale mais aussi des outils à assistance électrique pour se passer du tracteur sur certaines tâches.
      Plus largement, les paysan·nes engagé·es dans de l’auto-construction à nos côtés proposent des solutions
      techniques et agronomiques adaptées à une agro-écologie paysanne de</span> <span class="span37">proximité,
      résiliente et écologique</span><span class="span37">. Nous avons par exemple élaboré depuis 10 ans de nombreux
      outils de travail du sol et de gestion de l’enherbement, deux enjeux clefs en agriculture biologique. Nous
      essayons aussi d’encourager le bricolage et l’auto-construction de machines à partir d’outils déjà existants pour
      leur donner une seconde vie.</span>
    </p>
    <p class="para3">
      <span class="span37">Pour en savoir plus sur l’aventure, rendez-vous sur le</span> <a href=
      "https://www.latelierpaysan.org/Plaidoyer-souverainete-technologique-des-paysans"><span class="span54">site
      internet de l’Atelier Paysan</span></a><span class="span37">. Voir aussi le</span> <a href=
      "https://www.latelierpaysan.org/Plaidoyer-souverainete-technologique-des-paysans"><span class="span54">plaidoyer
      pour une souveraineté technologique</span></a> <span class="span37">du Pôle Inpact et le</span> <a href=
      "https://www.369editions.com/latelier-paysan/"><span class="span54">Manuel 369 consacré à l’Atelier
      Paysan</span></a><span class="span37">, Texte de Sarah Petitbon et Dessins de Louise Drulhe, 2019.</span>
    </p>
    <p class="para13">
      <span class="span5">L’arnaque des algorithmes d’aide à la prise de décision</span>
    </p>
    <p class="para23">
      <span class="span6">Bastien Le Que</span><span class="span6">rr</span><span class="span6">ec,</span> <span class=
      "span29">doctorant</span> <span class="span6">en droit public</span>
    </p>
    <p class="para23">
      <span class="span6">et</span> <span class="span6">militant à la</span> <span class="span2">Quadrature du
      Net</span>
    </p>
    <p class="para3">
      &nbsp;
    </p>
    <p class="para3">
      <span class="span2">L’administration, au sens public du terme, prend tous les jours un certain nombre de
      décisions</span><span class="span2">&nbsp;:</span> <span class="span2">lorsqu’elle accorde une allocation,
      lorsqu’elle retire un permis de conduire, lorsqu’elle accepte un·e étudiant·e dans une formation supérieure,
      lorsqu’elle est chargée d’appliquer une loi, etc. Décider est le quotidien de l’administration et administrer,
      nous dit le dictionnaire Larousse, signifie</span> <span class="span2">«&nbsp;</span><span class="span6">diriger,
      gérer des affaires publiques ou privées</span><span class="span6">&nbsp;»</span><span class="span2">. La
      Constitution nous prévient également que</span> <span class="span2">«&nbsp;</span><span class="span6">le
      Gouvernement détermine et conduit la politique de la nation</span><span class="span6">&nbsp;»</span> <span class=
      "span2">et</span> <span class="span2">«&nbsp;</span><span class="span6">dispose de
      l’administration</span><span class="span6">&nbsp;»</span> <span class="span2">(article 20). Le rôle de
      l’administration dans la conduite des affaires publiques est donc fondamental. À cette fin, son pouvoir de
      décision l’est tout autant.</span>
    </p>
    <p class="para3">
      <span class="span2">Décider est donc une fonction intrinsèque à l’administration, mais décider n’est pas toujours
      le fruit d’un processus entièrement humain. L’administration s’est toujours dotée de règles, de documents, de
      cadres, pour décider, quand bien même aucune obligation ne le lui imposerait</span><span class=
      "span2">&nbsp;:</span> <span class="span2">le pouvoir discrétionnaire dont jouit très souvent l’administration
      est limité par elle-même.</span>
    </p>
    <p class="para3">
      <span class="span2">De plus, l’arrivée ces derniers temps d’un nouvel outil pour l’administration, l’algorithme,
      change radicalement la manière dont on peut concevoir la décision administrative. Skip Machine lave plus blanc
      que blanc</span><span class="span2">&nbsp;;</span> <span class="span2">l’algorithme décide plus efficacement que
      l’humain. Il en résulte un miracle</span><span class="span2">&nbsp;:</span> <span class="span2">la décision
      administrative algorithmique. Le législateur est intervenu, pour répondre à un certain nombre de craintes. Mais
      la pratique administrative tend à contourner ces protections grâce à un nouvel outil, l’algorithme d’aide à la
      prise de décision.</span>
    </p>
    <p class="para3">
      <span class="span2">Avant toute chose, il est nécessaire de s’entendre sur la notion de décision et celle
      d’algorithme. Nous entendons ici un algorithme (ou son équivalent juridique de</span> <span class=
      "span2">«&nbsp;</span><span class="span2">traitement algorithmique</span><span class=
      "span2">&nbsp;»</span><span class="span2">) comme une suite d’opérations mathématiques avec en entrée plusieurs
      paramètres et en sortie un résultat unique (mais pas forcément reproductible, comme nous le verrons plus tard).
      Un algorithme n’a donc pas à être compliqué</span><span class="span2">&nbsp;:</span> <span class="span2">un
      rapport sénatorial a ainsi pu comparer une recette de cuisine à un algorithme</span><sup id=
      "calledF1"><a epub:type="noteref" href="#dataF1">50</a></sup><span class="span2">. Il ne s’agit pas forcément non
      plus d’un programme informatique ou de lignes de codes exécutables</span><span class="span2">&nbsp;:</span>
      <span class="span2">un algorithme peut également être une série de formules dans une feuille de
      calcul</span><sup id="calledF2"><a epub:type="noteref" href="#dataF2">51</a></sup><span class="span2">.</span>
    </p>
    <p class="para3">
      <span class="span2">On classera toutefois les algorithmes en deux catégories</span><span class=
      "span2">&nbsp;:</span> <span class="span2">les algorithmes auto-apprenants et les autres. Les premiers (on
      parlera également d’</span><span class="span2">«&nbsp;</span><span class="span2">intelligence
      artificielle</span><span class="span2">&nbsp;»</span><span class="span2">, de</span> <span class=
      "span2">«&nbsp;</span><span class="span6">machine learning</span><span class="span6">&nbsp;»</span> <span class=
      "span2">ou de</span> <span class="span2">«&nbsp;</span><span class="span6">deep learning</span><span class=
      "span6">&nbsp;»</span><span class="span2">) fonctionnent avec une phase d’apprentissage préalable. Dans un
      premier temps, l’algorithme auto-apprenant s’entraîne sur un jeu de données dont le résultat attendu est connu
      (par exemple</span><span class="span2">&nbsp;:</span> <span class="span2">«&nbsp;</span><span class="span6">cette
      image est un chaton</span><span class="span6">&nbsp;»</span> <span class="span2">ou</span> <span class=
      "span2">«&nbsp;</span><span class="span6">cette image n’est pas un chaton</span><span class=
      "span6">&nbsp;»</span><span class="span2">) et s’adapte en comparant ses résultats à ceux attendus. Une fois
      cette phase terminée, il est utilisé alors que le résultat</span> <span class="span2">attendu n’est pas connu
      (dans notre exemple, il sera censé distinguer les images de chatons des autres). Le résultat d’un algorithme
      auto-apprenant n’est pas reproductible puisqu’il dépendra de la phase d’apprentissage et de la qualité du jeu de
      données initial. Les autres algorithmes, ceux qui ne sont pas auto-apprenants, ont un résultat reproductible
      puisqu’il ne repose pas sur une phase préalable d’apprentissage.</span>
    </p>
    <p class="para3">
      <span class="span2">Une décision administrative, quant à elle, est un acte administratif (au sens de document
      émanant d’une administration</span><sup id="calledF3"><a epub:type="noteref" href=
      "#dataF3">52</a></sup><span class="span2">) décisoire. Lorsque l’administration constate quelque chose (ce que
      font beaucoup d’autorités de régulation, par exemple), elle ne fait pas de choix et son acte n’est donc pas une
      décision.</span>
    </p>
    <p class="para3">
      <span class="span2">Enfin, nous entendrons une décision administrative algorithmique comme un type de décision
      administrative dans laquelle un algorithme a été utilisé durant le processus de prise de décision. L’algorithme
      n’a pas à être le seul fondement à la décision pour que celle-ci soit qualifiable de décision administrative
      algorithmique. Il faut distinguer la décision algorithmique de l’algorithme d’aide à la prise de décision : le
      premier fonde la décision, le deuxième est utilisé en amont de la décision et ne la fonde alors pas.</span>
    </p>
    <p class="para3">
      <span class="span2">Arrêtons-nous tout d’abord sur ce qui motive l’administration à utiliser des algorithmes (I).
      Voyons ensuite les barrières prévues par le droit pour les décision</span><span class="span2">s</span>
      <span class="span2">algorithmique</span><span class="span2">s</span> <span class="span2">(II) et comment
      l’administration les contourne grâce aux algorithmes d’aide à la prise de décision (III). Enfin, étudions les
      conséquences de ces algorithmes d’aide à la prise de décision sur nos droits fondamentaux (IV).</span>
    </p>
    <p class="para4">
      <span class="span1">I. Un recours aux décisions algorithmiques de plus en plus important</span>
    </p>
    <p class="para3">
      <span class="span2">Il est difficile – pour ne pas dire impossible – de systématiser l’utilisation d’un
      algorithme. L’administration n’est jamais tenue d’y avoir recours, ce n’est qu’une faculté (explicitement admise
      par la loi depuis 2016</span><sup id="calledF4"><a epub:type="noteref" href="#dataF4">53</a></sup><span class=
      "span2">).</span>
    </p>
    <p class="para3">
      <span class="span2">En tout état de cause, lorsqu’elle y a recours, cela peut être pour atteindre deux objectifs.
      Premièrement, il peut s’agir d’une situation dans laquelle l’administration doit prendre beaucoup de décisions
      dans un laps de temps restreint. Elle veut alors accélérer la prise de décision. Dans ce cas, l’algorithme est
      souvent très simple et il s’agit principalement de décisions administratives individuelles (c’est-à-dire dont le
      destinataire est une personne nommée ou un groupe de personnes individualisées). Le cas des algorithmes locaux de
      Parcou</span><span class="span2">r</span><span class="span2">sup illustre parfaitement cette situation : les
      universités doivent, en quelques semaines, classer des milliers de candidatures en attribuant à chaque candidat
      un rang précis</span><span class="span2">&nbsp;;</span> <span class="span2">les algorithmes locaux de Parcoursup
      appliquent à l’ensemble des candidats une même règle pour donner</span> <span class="span6">in fine</span>
      <span class="span2">un rang à chaque candidature. Les algorithmes locaux de Parcoursup sont une simple feuille de
      calcul sur laquelle les commissions de classement ont donné une importance plus ou moins grande à certains
      critères académiques parmi ceux transmis par la plateforme aux universités (notes, appréciations, lycée
      d’origine, etc.</span><sup id="calledF5"><a epub:type="noteref" href="#dataF5">54</a></sup><span class=
      "span2">).</span>
    </p>
    <p class="para3">
      <span class="span2">Deuxièmement, il peut s’agir de détecter ce que l’on estime impossible à trouver par une
      analyse humaine</span><span class="span2">&nbsp;:</span> <span class="span2">il s’agit de la recherche de signaux
      faibles. Dans cette situation, le recours aux algorithmes auto-apprenants est le plus souvent nécessaire. Par
      exemple, la surveillance algorithmique des réseaux de communication (parfois appelée</span> <span class=
      "span2">«&nbsp;</span><span class="span2">boîtes noires</span><span class="span2">&nbsp;»</span><span class=
      "span2">) permises depuis la loi renseignement de 2015</span><sup id="calledF6"><a epub:type="noteref" href=
      "#dataF6">55</a></sup> <span class="span2">repose sur des algorithmes auto-apprenants dont le but est de détecter
      des risques à caractère terroriste qu’on estime indétectable par un analyste du renseignement.</span>
    </p>
    <p class="para4">
      <span class="span1">II. L’algorithme comme fondement de la décision administrative</span><span class=
      "span1">&nbsp;:</span> <span class="span1">une protection théorique contre les abus de la décision administrative
      algorithmique</span>
    </p>
    <p class="para3">
      <span class="span2">Ce panorama étant posé, une peur peut légitimement naître</span><span class=
      "span2">&nbsp;:</span> <span class="span2">comment être certain qu’un algorithme a pris la bonne
      décision</span><span class="span2">&nbsp;?</span> <span class="span2">Il est intellectuellement plus facile de
      contester une décision prise par un humain que de contester une décision prise par une machine dont l’aléatoire
      est réputé neutralisé.</span>
    </p>
    <p class="para3">
      <span class="span2">Le droit offre un certain nombre de mesures protectrices – bien qu’insuffisantes en pratique
      – lorsqu’un traitement algorithmique a été le fondement d’une décision. Autrement dit, lorsque l’administration,
      pour prendre sa décision, se base sur les résultats d’un algorithme, le droit pose des limites. L’article L.
      311-3-1 du code des relations entre le public et l’administration énonce ainsi le droit de se faire communiquer
      les</span> <span class="span2">«&nbsp;</span><span class="span6">règles définissant ce traitement ainsi que les
      principales caractéristiques de sa mise en œuvre</span><span class="span6">&nbsp;»</span><sup id=
      "calledF7"><a epub:type="noteref" href="#dataF7">56</a></sup> <span class="span2">dans le cas d’une décision
      administrative individuelle prise sur le fondement d’un traitement algorithmique. Ainsi, lorsque l’administration
      prend une décision individuelle à l’aide d’un algorithme, un droit à se faire communiquer certaines informations
      sur l’algorithme naît au bénéfice du destinataire de la décision. Une forme de transparence est ainsi posée et
      d’elle découle une forme de contrôle sur la qualité de l’algorithme, donc de la décision qui en découle.</span>
    </p>
    <p class="para3">
      <span class="span2">Le Conseil constitutionnel est également venu poser un garde-fou important à l’usage
      d’algorithmes dans les décisions administratives. Il a ainsi précisé que l’administration doit pouvoir expliquer
      et reproduire ses résultats</span><span class="span2">&nbsp;:</span> <span class="span2">les algorithmes
      auto-apprenants sont donc théoriquement exclus de la prise de décision.</span><sup id="calledF8"><a epub:type=
      "noteref" href="#dataF8">57</a></sup>
    </p>
    <p class="para3">
      <span class="span2">Enfin, précisons également que le code source des algorithmes sont des documents
      administratifs au sens de la loi.</span><sup id="calledF9"><a epub:type="noteref" href="#dataF9">58</a></sup>
      <span class="span2">À ce titre, il est possible, en dehors des cas de décisions administratives individuelles, de
      se faire communiquer de tels documents.</span><sup id="calledF10"><a epub:type="noteref" href=
      "#dataF10">59</a></sup>
    </p>
    <p class="para4">
      <span class="span1">III. L’algorithme comme simple aide</span><span class="span1">&nbsp;:</span> <span class=
      "span1">l’absence de toute garantie contre les algorithmes d’aide à la prise de décision</span>
    </p>
    <p class="para3">
      <span class="span2">La pratique administrative tend à exclure de plus en plus les algorithmes de la prise de
      décision. Si</span> <span class="span2">l’algorithme n’est plus considéré comme ayant fondé une décision, alors
      les limites posées (notamment l’interdiction de recourir à des algorithmes auto-apprenants donc aux résultats non
      reproductibles) n’existent plus du tout.</span>
    </p>
    <p class="para3">
      <span class="span2">C’est ce qu’il se passe avec le recours des algorithmes dits</span> <span class=
      "span2">«&nbsp;</span><span class="span2">d’aide à la prise de décision</span><span class=
      "span2">&nbsp;»</span><span class="span2">. Ces algorithmes sont utilisés bien en amont de la prise de
      décision</span><span class="span2">&nbsp;:</span> <span class="span2">il s’agit de guider l’administration dans
      son action au quotidien, avant qu’une décision ne soit prise. On retrouve de tels algorithmes par exemple dans la
      lutte contre la fraude fiscale et douanière, dans la lutte contre le terrorisme, la police prédictive,
      etc.</span>
    </p>
    <p class="para3">
      <span class="span2">Ces algorithmes d’aide à la prise de décision fonctionnent selon une même logique : une
      alerte ou une recommandation est levée par l’algorithme. Un·e agent de l’administration reçoit cette alerte ou
      cette recommandation, puis décide de prendre ou non une décision. Le fondement de la décision n’est donc plus
      l’algorithme, qui a seulement invité l’agent à s’intéresser à une situation particulière. L’algorithme d’aide à
      la prise de décision n’est plus au fondement de la décision, il est détaché.</span>
    </p>
    <p class="para3">
      <span class="span2">Ainsi, l’algorithme</span> <span class="span6">Paved</span> <span class=
      "span2">(«&nbsp;plateforme d’analyse et de visualisation évolutive de la délinquance&nbsp;») de la gendarmerie ne
      fait qu’afficher les zones à risques</span><span class="span2">&nbsp;:</span> <span class="span2">il ne détermine
      pas les zones dans lesquelles les patrouilles seront positionnées. L’agent choisira seul·e de placer ses
      patrouilles dans les zones à risque ou non. Il en va de même pour les boites noires utilisées par les services de
      renseignement (cf.</span> <span class="span6">supra</span> <span class="span2">pour leur
      présentation)</span><span class="span2">&nbsp;:</span> <span class="span2">elles ne lèvent qu’une alerte sur une
      potentielle menace, libre ensuite à l’analyste du renseignement de procéder ou non à une surveillance plus
      ciblée. Ce même fonctionnement vaut également pour les algorithmes de Bercy chargés de détecter les potentielles
      fraudes fiscales</span><span class="span2">&nbsp;:</span> <span class="span2">les agents du fisc sont toujours
      libres de procéder ou non au contrôle fiscal.</span>
    </p>
    <p class="para3">
      <span class="span2">Ces exemples sont réels et l’hypocrisie est flagrante. Si l’administration demande à un
      algorithme de l’aider, soit en augmentant le nombre de situations traitées, soit en détectant ce qu’un humain ne
      pourrait pas voir, pourquoi ne pas suivre ses recommandations</span><span class="span2">&nbsp;?</span>
      <span class="span2">On pourrait répondre que lorsqu’une alerte ou une recommandation est émise, l’agent pourrait
      refaire le traitement sur la situation spécifique afin de vérifier la qualité du résultat de l’algorithme.
      Cependant, premièrement, aucune obligation n’impose à l’administration une telle vérification. Deuxièmement, ce
      serait omettre les résultats négatifs qui impliquent une forme de validation de la situation par l’algorithme.
      Troisièmement, ce serait réduire drastiquement les gains de productivité demandés à ces algorithmes dans
      certaines situations. Quatrièmement, enfin, certains cas ne se prêtent tout simplement pas à une telle
      vérification, notamment lorsqu’il est demandé à l’algorithme de repérer les signaux faibles.</span>
    </p>
    <p class="para3">
      <span class="span2">En réalité, lorsque une alerte ou une recommandation est levée par un algorithme d’aide à la
      prise de décision, l’administration se bornera à vérifier les erreurs grossières pour les cas positifs. Elle ne
      vérifiera jamais les résultats négatifs. L’humain chargé de réceptionner les alertes ou recommandations n’aura
      qu’un rôle de vérification</span> <span class="span6">a minima</span><span class="span2">, au risque, autrement,
      d’aller à l’encontre des gains de production demandés. Le doute sera donc nécessairement au détriment de
      l’administré·e. Éventuellement, il peut être demandé à l’agent d’opérer un classement pour ne prendre en
      considération qu’un nombre limité de cas. On peut penser qu’un tel choix est fait dans les domaines où un
      contingentement existe en fait ou en droit (nombre limité de gendarmes mobilisables sur le terrain, quota de
      mises sous surveillance, etc.). Mais rien n’indique que ce choix ne soit pas dû au hasard</span> <span class=
      "span2">(notamment lorsque l’humain n’est pas censé pouvoir apprécier la situation).</span>
    </p>
    <p class="para4">
      <span class="span1">IV. Des conséquences négatives concrètes sur les droits fondamentaux</span>
    </p>
    <p class="para3">
      <span class="span2">Le résultat de tout cela est assez décevant. D’une part, l’usage même de ces algorithmes
      d’aide à la prise de décision implique un droit à un recours effectif limité. Dès 2016</span><sup id=
      "calledF11"><a epub:type="noteref" href="#dataF11">60</a></sup><span class="span2">, la Cour suprême du Wisconsin
      affirmait qu’il n’est pas possible de contester le résultat d’un algorithme d’aide à la prise de décision puisque
      seul l’humain a pris la décision</span><span class="span2">&nbsp;:</span> <span class="span2">la seule décision
      attaquable devant un juge est celle prise par un humain, et elle seule, même si un algorithme a aidé à cette
      prise de décision. Il n’existe donc pas de recours direct contre ces algorithmes puisqu’ils sont passés par le
      truchement d’un humain avant la prise de décision en tant que telle.</span>
    </p>
    <p class="para3">
      <span class="span2">Mais, même dans le cas des décisions administratives algorithmiques – c’est-à-dire celles
      dont le fondement est un algorithme, contrairement au cas des algorithmes d’aide à la prise de décision --, les
      droits fondamentaux sont limités. Dans ces situation</span><span class="span2">s</span><span class="span2">, on
      se heurtera au pouvoir discrétionnaire de l’administration</span><span class="span2">&nbsp;:</span> <span class=
      "span2">l’administration, très souvent, a une large possibilité d’action et le rôle du juge se limite à vérifier
      l’absence d’</span><span class="span2">«&nbsp;</span><span class="span2">erreur manifeste
      d’appréciation</span><span class="span2">&nbsp;»</span><span class="span2">, c’est-à-dire l’absence d’erreur
      grossière. Une décision administrative algorithmique ne sera qu’une décision dans laquelle l’administration a
      voulu, de son chef, limiter son aléa. Mais la manière de le limiter, les paramétrages de l’algorithme, restent un
      choix qui n’est pas vraiment contestable. La transparence (lorsqu’elle est applicable) permettra à l’administré·e
      de vérifier ces erreurs grossières (on peut par exemple penser aux cas de discriminations), mais le doute se fera
      toujours au bénéfice de l’administration.</span>
    </p>
    <p class="para3">
      <span class="span2">D’autre part, l’usage de tels algorithmes va de pair avec une augmentation du nombre de
      données traitées. Pour utiliser des algorithmes, encore faut-il avoir des informations pour les nourrir.
      L’administration est donc incitée à collecter et traiter de plus en plus de données. La récente volonté de Bercy
      de récolter les données publiques des réseaux sociaux n’est que le dernier exemple d’une liste très longue. Avec
      cette collecte, ce sont le droit à la vie privée et familiale ou encore le droit à la liberté d’expression et
      d’information qui se retrouvent limités.</span>
    </p>
    <p class="para3">
      <span class="span37">Le résultat n’est pas réjouissant. L’administration se sert d’algorithmes, mais parfois
      tellement en amont dans son travail qu’il</span><span class="span37">s</span> <span class="span37">ne sont pas
      considérés comme ayant fondé la décision administrative, sapant au passage les garanties posées par le droit. Un
      problème de taille se pose</span><span class="span37">&nbsp;:</span> <span class="span37">la notion de décision
      administrative, telle qu’elle est conçue aujourd’hui, a-t-elle encore une légitimité à l’heure des
      algorithmes&nbsp;? Doit-elle évoluer pour réintégrer dans son champ les algorithmes d’aide à la prise de
      décision&nbsp;?</span>
    </p>
    <p class="para13">
      <span class="span5">Les algorithmes, «&nbsp;armes de destruction mathématiques&nbsp;»</span>
    </p>
    <p class="para3">
      &nbsp;
    </p>
    <p class="para3">
      <span class="span51">La mathématicienne et «&nbsp;scientifique des données&nbsp;» Cathy O'Neil, ex-analyste à
      Wall Street et militante du mo</span><span class="span51">u</span><span class="span51">vement Occupy, a publié en
      2018 son livre «&nbsp;Algorithmes. La bombe à retardement&nbsp;».&nbsp;Elle y présente une analyse problématisée
      de</span> <span class="span51">l’</span><span class="span51">impact</span> <span class=
      "span51">d’</span><span class="span51">une société qui livre de plus en plus de décisions sociales fondamentales
      à des algorithmes. Voici une courte synthèse de ses principaux arguments.&nbsp;</span>
    </p>
    <p class="para3">
      <span class="span2">Les algorithmes, de même que tout ce qui est associé à la science et à la technologie, ont
      tendance à être perçus comme un mécanisme objectif, neutre, extérieur aux complexités sociales. Or, argumente
      Cathy O'Neil, les algorithmes sont plutôt le reflet</span> <span class="span2">d’</span><span class=
      "span2">opinions non-scientifiques des développeurs, qui contrôlent et prennent les décisions sur leur production
      finale. En particulier,</span> <span class="span2">c’</span><span class="span2">est le type de données à utiliser
      et la définition du résultat attendu qui, en</span> <span class="span2">soi</span><span class="span2">, est
      sensible aux biais sociaux et idéologiques de ces développeurs.&nbsp;</span>
    </p>
    <p class="para3">
      <span class="span2">Sans réflexion critique préalable, les algorithmes en arrivent à reproduire, voire amplifier,
      les inégalités sociales. Par exemple, si un algorithme doit déterminer quel·les candidat·es ont le plus de
      chance</span> <span class="span2">d’</span><span class="span2">être embauché·es à Fox News (pour reprendre
      l</span><span class="span2">’</span><span class="span2">exemple développé par la mathématicienne), il se basera
      sur les caractéristiques sociales des dirigeants historiques de la chaîne de télévision : hommes, blancs, de
      classes moyennes ou supérieur</span><span class="span2">e</span><span class="span2">s. Les femmes auraient
      beaucoup moins de probabilité</span> <span class="span2">d’</span><span class="span2">être sélectionnées
      par</span> <span class="span2">l’</span><span class="span2">algorithme car, dans le passé</span> <span class=
      "span2">elles</span> <span class="span2">n</span><span class="span2">’</span><span class="span2">avaient pas
      accès à ces postes</span><span class="span2">&nbsp;:</span> <span class="span2">en un sens, le passé définit le
      futur. Ainsi, si on construit un algorithme à partir</span> <span class="span2">d’</span><span class="span2">une
      culture discriminatoire, les inégalités ne peuvent être que reproduites et amplifiées par les calculs
      automatisés.&nbsp;</span>
    </p>
    <p class="para3">
      <span class="span2">Selon cette auteure, les algorithmes sont des «&nbsp;armes de destructions
      mathématiques&nbsp;»</span><sup id="calledF12"><a epub:type="noteref" href="#dataF12">61</a></sup> <span class=
      "span2">pour trois raisons.</span>
    </p>
    <p class="para3">
      <span class="span2">Il</span> <span class="span2">s’</span><span class="span2">agit</span> <span class=
      "span2">d’</span><span class="span2">un système de notation qui prend des décisions graves, importantes, à fort
      impact sur la vie des personnes ;</span>
    </p>
    <p class="para3">
      <span class="span2">Leur fabrication est maintenue secrète, tout autant que la nature des données prises en
      compte et des définitions du résultat à atteindre ;</span>
    </p>
    <p class="para3">
      <span class="span2">Les algorithmes sont fondamentalement injustes, car ils creusent les inégalités
      sociales.&nbsp;</span>
    </p>
    <p class="para3">
      <span class="span2">L’</span><span class="span2">exemple paradigmatique de cela est</span> <span class=
      "span2">l’</span><span class="span2">algorithme de prédiction de récidive utilisé par le système
      judicia</span><span class="span2">i</span><span class="span2">re états-unien. En obtenant un score élevé, une
      personne condamnée reçoit une peine de prison plus longue pour «&nbsp;éviter la récidive&nbsp;». Or, les données
      utilisées présentent un biais raciste évident</span><span class="span2">&nbsp;:</span> <span class="span2">le
      taux de criminalité du quartier de résidence (dans un pays géographiquement très ségrégué), si le père du détenu
      a fait de la prison,</span> <span class="span2">s’</span><span class="span2">il touche des prestations
      sociales</span><span class="span2">…</span> <span class="span2">Des éléments que la population afro-états-unienne
      a beaucoup plus de probabilité de rassembler. Les hommes noirs se retrouvent donc à écoper des peines de prison
      bien plus longues que les hommes blancs pour les mêmes délits ou crimes. Cet algorithme, mis en place à l'origine
      pour contrebalancer le racisme notoire de certain·es juges états-</span><span class="span2">unien·nes grâce à des
      mesures «&nbsp;objectives&nbsp;», finit par inscrire en son sein même le racisme</span> <span class=
      "span2">qu’</span><span class="span2">il était censé combattre –voire pire, car la croyance en</span>
      <span class="span2">l’</span><span class="span2">objectivité de</span> <span class="span2">l’</span><span class=
      "span2">algorithme rend plus invisible</span><span class="span2">s</span> <span class="span2">les dynamiques
      racistes à</span> <span class="span2">l’œuvre.</span><span class="span2">&nbsp;</span>
    </p>
    <p class="para3">
      <span class="span2">Le problème réside donc</span> <span class="span2">d’</span><span class="span2">un côté, en
      cette fausse impression de la neutralité des algorithmes, et de</span> <span class="span2">l’</span><span class=
      "span2">autre, en</span> <span class="span2">l’</span><span class="span2">absence de conscience sociale des
      développeurs informatiques qui ne se sentent pas responsable de leur production technologique sur le plan
      éthique. Aucun garde-fou ne leur est</span> <span class="span2">d’</span><span class="span2">ailleurs opposé,
      car</span> <span class="span2">l’</span><span class="span2">idée</span> <span class=
      "span2">qu’</span><span class="span2">ils «&nbsp;savent ce</span> <span class="span2">qu’</span><span class=
      "span2">ils font car ils ont un doctorat&nbsp;» est largement répandue. Les algorithmes deviennent ainsi un
      mécanisme pour éluder les responsabilités personnelles et collectives face aux erreurs commises et aux injustices
      sociales.&nbsp;</span>
    </p>
    <p class="para3">
      <span class="span2">Il est donc urgent, rappelle O'Neil,</span> <span class="span2">d’</span><span class=
      "span2">exiger collectivement un droit de regard citoyen sur la fabrication et</span> <span class=
      "span2">l’</span><span class="span2">utilisation des algorithmes</span><span class="span2">&nbsp;;</span>
      <span class="span2">qu’</span><span class="span2">il soit possible de pousser les responsables techniques et
      politiques à rendre des comptes sur ces utilisations</span><span class="span2">&nbsp;;</span> <span class=
      "span2">et que soient mis en place des mécanismes</span> <span class="span2">d’</span><span class="span2">appels
      de décisions prises par algorithmes.&nbsp;</span>
    </p>
    <p class="para3">
      &nbsp;
    </p>
    <p class="para3">
      &nbsp;
    </p>
    <p class="para3">
      &nbsp;
    </p>
    <p class="para3">
      &nbsp;
    </p>
    <p class="para3">
      &nbsp;
    </p>
    <p class="para3">
      &nbsp;
    </p>
    <p class="para3">
      &nbsp;
    </p>
    <p class="para12">
      <span class="span17">P</span><span class="span17">ARTIE II</span> <span class="span17">: D</span><span class=
      "span17">ES ENJEUX ENVIRONNEMENTAUX</span>
    </p>
    <p class="para13">
      <span class="span56">L</span><span class="span56">e Numérique, outil ou handicap pour la transition
      énergétique</span><span class="span56">&nbsp;?</span>
    </p>
    <p class="para6">
      <span class="span24">The Shift Project, think tank de la transition carbonne</span>
    </p>
    <p class="para6">
      &nbsp;
    </p>
    <p class="para3">
      <span class="span24">Ce texte est la republication de l’introduction au rapport «&nbsp;</span><span class=
      "span24">Pour une sobriété numérique&nbsp;»</span><sup id="calledF13"><a epub:type="noteref" href=
      "#dataF13">62</a></sup><span class="span24">,</span> <span class="span24">élaboré par le</span> <span class=
      "span28">Shift Project,</span> <span class="span24">disponible en ligne</span><sup id="calledF14"><a epub:type=
      "noteref" href="#dataF14">63</a></sup>
    </p>
    <p class="para3">
      &nbsp;
    </p>
    <p class="para3">
      <span class="span28">La consommation d’énergie du numérique est aujourd’hui en hausse de</span> <span class=
      "span28">9&nbsp;</span><span class="span28">% par an. Il est possible de la ramener à</span> <span class=
      "span28">1,5&nbsp;</span><span class="span28">% par an en adoptant la</span> <span class=
      "span28">«&nbsp;</span><span class="span28">Sobriété numérique</span><span class="span28">&nbsp;»</span>
      <span class="span28">comme principe d’action. La transition numérique telle qu’elle est actuellement mise en
      œuvre participe au dérèglement climatique plus qu’elle n’aide à le prévenir. Il est urgent d’agir.</span>
      <span class="span28">C’est ce que conclut le</span> <a href=
      "https://theshiftproject.org/wp-content/uploads/2018/11/Rapport-final-v8-WEB.pdf"><span class="span22">rapport
      sur l’impact environnemental du numérique publié le 4 octobre</span></a> <span class="span2">2018</span>
      <span class="span28">par</span> <span class="span24">The Shift Project</span><span class="span28">, think tank de
      la transition carbone, quatre jours avant la publication du rapport spécial du GIEC sur un monde</span>
      <span class="span28">avec un réchauffement de</span> <span class="span28">+</span><span class=
      "span28">1,5&nbsp;</span><span class="span28">°C. Cet impact environnemental doit être adressé, faute de quoi le
      numérique fera davantage partie du problème que de la solution.</span>
    </p>
    <p class="para3">
      <span class="span28">Le numérique étant reconnu comme un levier de développement économique et social, la
      transition numérique apparaît comme incontournable pour l’ensemble des pays et des entreprises.</span>
      <span class="span28">La transition numérique est</span> <span class="span26">en outre souvent considérée comme un
      moyen de réduire la consommation d’énergie dans un grand nombre de secteurs. Pourtant, les impacts
      environnementaux directs et indirects (</span><span class="span26">«&nbsp;</span><span class="span26">effets
      rebond</span><span class="span26">&nbsp;»</span><span class="span26">) liés aux usages croissants du numérique
      sont systématiquement sous-estimés.</span>
    </p>
    <p class="para4">
      <span class="span1">Un numérique de plus en plus vorace en énergie</span>
    </p>
    <p class="para3">
      <span class="span28">Le développement rapide du numérique génère une augmentation forte de son empreinte
      énergétique directe.</span> <span class="span28">Cette empreinte inclut l’énergie de fabrication et d’utilisation
      des équipements (serveurs, réseaux, terminaux). Elle est en progression rapide, de</span> <span class=
      "span28">9&nbsp;</span><span class="span28">% par an. La consommation d’énergie directe occasionnée par un euro
      investi dans le numérique a augmenté de</span> <span class="span28">37&nbsp;</span><span class="span28">% depuis
      2010.</span> <span class="span28">L’intensité énergétique de l’industrie numérique augmente de</span>
      <span class="span28">4&nbsp;</span><span class="span28">% par an</span><span class="span28">&nbsp;:</span>
      <span class="span28">une hausse à contre-courant de l’évolution de l’intensité énergétique du PIB mondial,
      laquelle décroît actuellement de</span> <span class="span28">1,8&nbsp;</span><span class="span28">% chaque année.
      L’explosion des usages vidéo (Skype, streaming, etc.) et la multiplication des périphériques numériques
      fréquemment renouvelés sont les principaux facteurs de cette inflation énergétique.</span>
    </p>
    <p class="para4">
      <span class="span1">Lourd bilan carbone pour la transition numérique</span>
    </p>
    <p class="para3">
      <span class="span28">La part du numérique dans les émissions de gaz à effet de serre a augmenté de moitié depuis
      2013, passant de</span> <span class="span28">2,5&nbsp;</span><span class="span28">% à</span> <span class=
      "span28">3,7&nbsp;</span><span class="span28">% du total des émissions mondiales.</span> <span class="span28">Les
      émissions de CO2 du numérique ont augmenté depuis 2013 d’environ 450 millions de tonnes dans l’OCDE, dont les
      émissions globales ont diminué de 250MtCO2eq.</span>
    </p>
    <p class="para3">
      <span class="span28">La transition numérique capte des ressources nécessaires à la transition énergétique.</span>
      <span class="span28">La captation d’une</span> <span class="span28">part progressivement démesurée de
      l’électricité disponible accroît la tension sur la production électrique à l’heure où celle-ci peine à se
      décarboner. L’augmentation de la production d’équipements numériques nécessite des quantités croissantes de
      métaux rares et critiques, également indispensables aux technologies énergétiques bas-carbone, alors que des
      facteurs physiques, géopolitiques et économiques commencent déjà à limiter leur disponibilité.</span>
    </p>
    <p class="para4">
      <span class="span1">Le numérique,</span> <span class="span1">«&nbsp;</span><span class="span1">c’est pas
      automatique</span><span class="span1">&nbsp;»</span>
    </p>
    <p class="para3">
      <span class="span28">La contribution nette du numérique à la réduction de l’impact environnemental reste donc à
      démontrer</span><span class="span28">, secteur par secteur, en prenant garde aux nombreux</span> <span class=
      "span28">«&nbsp;</span><span class="span28">effets rebond</span><span class="span28">&nbsp;»</span><span class=
      "span28">. De fait, le numérique manifeste une tendance exactement inverse à celle qui lui est généralement
      attribuée</span><span class="span28">&nbsp;:</span> <span class="span28">dématérialiser l’économie. Nous
      constatons que les évolutions actuelles des impacts environnementaux du numérique vont à l’encontre des objectifs
      de découplage énergétique et climatique du PIB fixés par l’Accord de Paris sur le climat signé en 2015.</span>
    </p>
    <p class="para3">
      <span class="span28">Les impacts attendus de la transition numérique sur la productivité et la croissance ne sont
      pas visibles</span> <span class="span28">dans les pays développés sur les</span> <span class="span28">cinq</span>
      <span class="span28">dernières années. Le taux de croissance de la zone OCDE reste stable autour de</span>
      <span class="span28">2&nbsp;</span><span class="span28">%, alors que la croissance des dépenses numériques est
      passée de</span> <span class="span28">3&nbsp;</span><span class="span28">% à plus de</span> <span class=
      "span28">5&nbsp;</span><span class="span28">% par an</span><span class="span28">&nbsp;:</span> <span class=
      "span28">décidément, les effets attendus du numérique sont loin d’</span><span class="span26">être
      automatiques.</span>
    </p>
    <p class="para4">
      <span class="span1">Les pays développés seuls responsables</span>
    </p>
    <p class="para3">
      <span class="span28">La consommation numérique actuelle est très polarisée.</span> <span class="span28">Les
      profils de consommation numérique sont extraordinairement contrastés. En moyenne en 2018, un Américain possède
      près de</span> <span class="span28">dix</span> <span class="span28">périphériques numériques connectés et
      consomme 140 Gigaoctets de données par mois. Un Indien possède en moyenne un seul périphérique et consomme 2
      Gigaoctets.</span>
    </p>
    <p class="para3">
      <span class="span28">La surconsommation actuelle n’est pas généralisée</span><span class="span28">&nbsp;:</span>
      <span class="span28">elle est le fait des pays développés, pour lesquels l’enjeu clé consiste à reprendre le
      contrôle de leurs usages.</span> <span class="span28">Partout dans le monde, il s’agit de planifier et de
      prioriser les investissements dans le numérique, afin de s’assurer qu’i</span><span class="span26">ls servent
      efficacement les politiques sectorielles (sachant que les pays en développement en retireront le plus de gains,
      en raison des infrastructures encore à créer).</span>
    </p>
    <p class="para4">
      <span class="span1">L’impact environnemental de la transition numérique devient gérable si elle est plus
      sobre</span>
    </p>
    <p class="para3">
      <span class="span24">The Shift Project</span> <span class="span28">propose une définition de la sobriété
      numérique</span><span class="span28">&nbsp;:</span> <span class="span28">acheter les équipements les moins
      puissants possibles, les changer le moins souvent possible et réduire les usages énergivores superflus.</span>
      <span class="span28">La sobriété numérique est une approche</span> <span class="span28">«</span><span class=
      "span24">&nbsp;</span><span class="span24">lean</span><span class="span28">&nbsp;»</span><span class="span28">,
      autrement dit au plus juste, qui est aussi source d’efficacité – énergétique, humaine, financière – pour les
      organisations. Son principe</span> <a href=
      "https://www.greenit.fr/2018/10/02/societe-sempare-de-sobriete-numerique/"><span class="span22">étend au niveau
      sociétal la prise en compte des objectifs poursuivis par les approches techniques de type</span></a> <a href=
      "https://www.greenit.fr/2018/10/02/societe-sempare-de-sobriete-numerique/"><span class=
      "span22">«&nbsp;</span></a><a href=
      "https://www.greenit.fr/2018/10/02/societe-sempare-de-sobriete-numerique/"><span class="span22">Green
      IT</span></a><span class="span2">&nbsp;»,</span> <span class="span28">destinées prioritairement aux Directions
      des systèmes informatiques (DSI), et confirme l’importance et la pertinence de ces approches.</span>
    </p>
    <p class="para3">
      <span class="span28">Passer de l’intempérance à la sobriété dans notre relation au numérique</span> <span class=
      "span28">permet de ramener</span> <span class="span28">l’augmentation de consommation d’énergie du numérique
      à</span> <span class="span28">1,5&nbsp;</span><span class="span28">%, ce qui n’est que similaire à la tendance
      globale tous secteurs confondus (…et n’est donc pas en soi compatible avec les objectifs de l’Accord de Paris).
      La mise en œuvre de la sobriété numérique telle que nous l</span><span class="span26">a proposons permettrait
      donc seulement de contenir l’explosion en cours de l’empreinte environnementale du numérique. Telle qu’elle est
      représentée dans notre scénario 2018-2025 “Sobriety”, cette sobriété numérique ne remettrait pas en cause le
      principe de la transition numérique. Ainsi, dans ce scénario, le volume de données échangées continue à croître
      et le nombre de smartphones et téléviseurs produits chaque année se stabilise au niveau de 2017 – alors que les
      marchés des pays développés sont déjà aujourd’hui proches de la saturation.</span>
    </p>
    <p class="para4">
      <span class="span1">Tous concernés par la sobriété numérique</span>
    </p>
    <p class="para3">
      <span class="span28">Accélérer la prise de conscience de l’impact environnemental du numérique</span><span class=
      "span28">, dans les entreprises et organisations publiques, dans le monde de la recherche et au sein du grand
      public, est un préalable. Cette prise de conscience permettra d’intégrer l’impact du numérique comme critère de
      décision dans toutes les politiques d’achat et d’utilisation des équipements électroniques. La prise de
      conscience et l’action doivent se faire à l’échelle européenne et avec les organisations internationales, compte
      tenu de l’envergure mondiale et de la puissance économique des acteurs principaux du numérique.</span>
    </p>
    <p class="para3">
      <span class="span28">Les organisations publiques et privées peuvent jouer un rôle majeur, en pilotant
      environnementalement leur transition numérique… à condition qu’elles disposent de références et d’outils
      adéquats.</span> <span class="span28">Elles doivent pouvoir prendre en compte l’impact environnemental de la
      composante numérique des choix qu’elles envisagent, à différents niveaux de pilotage.</span>
    </p>
    <p class="para3">
      <span class="span24">The Shift Project</span> <span class="span28">a développé de tels outils.</span>
      <span class="span28">Le Référentiel</span> <span class="span28">e</span><span class="span28">nvironnemental
      du</span> <span class="span28">n</span><span class="span28">umérique (REN) proposé par le</span> <span class=
      "span24">Shift</span> <span class="span28">donne, de manière accessible, des ordres de grandeur vérifiés sur
      l’énergie et les matières premières mobilisées</span> <span class="span28">par la production et l’utilisation de
      technologies numériques courantes. Le Shift propose à la puissance publique de fonder une base de données
      publique (sur le modèle de la base carbone de l’Ademe) pour permettre aux acteurs d’analyser leur impact
      environnemental. Grâce à cela, il sera possible de procéder à un bilan carbone des grands projets numériques
      avant de les lancer. Le</span> <span class="span24">Shift</span> <span class="span28">propose également aux
      dirigeants des mesures leur permettant d’agir sur la demande et la consom</span><span class="span26">mation de
      services numériques et, à l’État, des principes de politiques publiques pour limiter cet impact. Ces outils sont
      destinés à la fois aux pays en développement et aux pays développés.</span>
    </p>
    <p class="para4">
      <span class="span1">Retrouver une capacité à interroger l’utilité sociale et économique de nos
      comportements</span>
    </p>
    <p class="para3">
      <span class="span28">Il est nécessaire de retrouver une capacité individuelle et collective à interroger
      l’utilité sociale et économique de nos comportements d’achat et de consommation d’objets et de services
      numériques</span><span class="span28">, et d’adapter nos comportements en conséquence. La sobriété numérique doit
      être adoptée comme un principe d’action. La pression de l’offre (GAFAM, BATX*) et les attentes de croissance du
      PIB associées à la numérisation ne peuvent servir de seuls juges dans la sélection des projets numériques.</span>
    </p>
    <p class="para3">
      <span class="span28">Les entreprises ont un rôle clé à jouer et beaucoup à gagner</span> <span class="span28">–
      notamment la poursuite durable de leur transition numérique et la limitation des coûts.</span>
    </p>
    <p class="para3">
      <span class="span28">Dans les pays en développement, les gains économiques, environnementaux et sociaux
      potentiels promettent d’être plus importants</span> <span class="span28">car les infrastructures y sont encore
      largement à créer.</span>
    </p>
    <p class="para3">
      <span class="span28">Dans les pays développés, il serait grand temps de s’interroger davantage sur les multiples
      facettes – sociales, sanitaires, etc. – de la surconsommation numérique</span><span class="span28">, en
      complément de l’impact environnemental généré.</span> <span class="span28">Chiche ?</span>
    </p>
    <p class="para3">
      <span class="span27">*GAFAM (Google, Apple, Facebook, Amazon, Microsoft), BATX (Baidu, Alibaba, Tencent
      Xiaomi)</span>
    </p>
    <p class="para3">
      <span class="span26">—</span>
    </p>
    <p class="para3">
      <span class="span28">Le</span> <a href=
      "https://theshiftproject.org/wp-content/uploads/2018/11/Rapport-final-v8-WEB.pdf"><span class=
      "span3">rapport&nbsp;« Pour une sobriété numérique&nbsp;»</span></a><span class="span28">&nbsp;du think
      tank&nbsp;</span><span class="span24">The Shift Project</span><span class="span28">&nbsp;est le fruit d’un groupe
      de travail dirigé par Hugues Ferreboeuf</span><span class="span28">, in</span><span class="span26">génieur
      polytechnicien et diplômé de Télécom ParisTech qui a dirigé plusieurs sociétés du secteur numérique. Le groupe de
      travail est composé d’universitaires, d’experts et de professionnels du secteur</span><span class=
      "span26">&nbsp;:</span> <span class="span26">Françoise Berthoud (CNRS, GDS EcoInfo), Philippe Bihouix (exp.
      métaux), Pierre Fabre (AFD), Daniel Kaplan (FING), Laurent Lefèvre (INRIA), Alexandre Monnin (INRIA, ESC-Clermont
      Origens Medialab), Olivier Ridoux (IRISA, Université de Rennes), Samuli Vaija (exp. ACV), Marc Vautier (exp.
      éco-conception), Xavier Verne (exp. grands projets informatiques), Alain Ducass (exp. énergie et numérique en
      Afrique), Maxime Efoui-Hess (TSP), Zeynep Kahraman (TSP).</span>
    </p>
    <p class="para13">
      <span class="span57">Technocritique et écologie&nbsp;:</span> <span class="span57">les</span> <span class=
      "span57">années 1970</span>
    </p>
    <p class="para23">
      <span class="span14">François Jarrige,</span> <span class="span14">h</span><span class="span14">istorien</span>
    </p>
    <p class="para3">
      &nbsp;
    </p>
    <p class="para3">
      &nbsp;
    </p>
    <p class="para3">
      <span class="span2">À la fin des années 1960, tandis que la question écologique s’affirme, les techniques
      pénètrent de plus en plus dans le champ de la critique sociale et politique. Alors que les oppositions aux grands
      équipements et aux politiques de modernisation des années 1945-1960 souffraient d’un manque de visibilité dans
      l’espace public et d’un déficit d’assises théoriques, celles des années 1970 montent en puissance et deviennent
      plus visibles (Pessis, Topçu et Bonneuil, 2013). Alors que le cadrage modernisateur des dites «&nbsp;Trente
      Glorieuses&nbsp;» entre en crise, les alertes environnementales ne cessent en effet de monter en puissance, les
      pollutions s’affirment comme une préoccupation majeure et la durabilité du monde industriel et de son système
      technique sont de plus en plus remis en cause. Les années 1968 représentent à cet égard un tournant en ce
      qu’elles marquent «&nbsp;un âge d’or des luttes&nbsp;» et conduisent à contester tous les pouvoirs établis, qu’il
      s’agisse de</span> <span class="span2">l’État</span><span class="span2">, des entreprises comme de toutes les
      grandes organisations (Mathieu, 2010). Les grèves ouvrières et les révoltes étudiantes bouleversent les
      représentations antérieures, modèlent de nouveaux répertoires d’action et inaugurent un nouveau cycle de
      radicalité et d’insubordination. Le seuil des années 1970, considéré comme le point d’achèvement de la période
      héroïque des «&nbsp;Trente Glorieuses&nbsp;», est par ailleurs traversé de multiples crises socio-écologiques qui
      amènent à interroger les trajectoires antérieures</span><span class="span2">&nbsp;:</span> <span class=
      "span2">choc pétrolier, crises monétaires, publication du rapport du club de Rome annonçant la fin de la
      croissance dans un monde fini, débats autour du choix nucléaire, contestations du gigantisme technicien et
      scientifique et de ses nuisances. La technique cesse d’être un donné naturel non questionnable et est de plus en
      plus perçue comme un enjeu politique qui doit être mis en débat. Les pensées critiques et les alertes contre les
      risques d’un développement technologique sans contrôle s’étendent alors que l’écologie politique offre un langage
      alternatif aux anciens idiomes politiques.</span>
    </p>
    <p class="para3">
      <span class="span2">Au début des années 1970, les analyses critiques de la technologie et les tentatives pour
      dévoiler ses enjeux et ses mythes se multiplient dans le champ intellectuel. Les techniques cessent d’être
      pensées comme de simples moyens, neutres, permettant d’accroître la maîtrise sur le monde au bénéfice du plus
      grand nombre, pour devenir de plus en plus les symptômes d’une modernité en crise. L’apparition du mot
      technocritique, un néologisme forgé par le philosophe-ingénieur Jean-Pierre Dupuy comme titre d’une collection
      très «&nbsp;illichienne&nbsp;» lancée aux éditions du Seuil en 1975, est caractéristique de cette recomposition
      du langage et du champ intellectuel. Par ce terme, il s’agissait de contester l’idée que «&nbsp;la technique est
      neutre, qu’elle fera le bien et le mal selon les intentions de ceux qui la gèrent&nbsp;». Comme l’énonçait le
      texte de présentation de cette collection</span><span class="span2">&nbsp;:</span> <span class="span2">«&nbsp;les
      maux et les frustrations dont souffre l’humanité ne sont pas dus simplement à des “bavures” ou à une
      planification défectueuse de la société industrielle, mais découlent inévitablement de caractéristiques
      intrinsèques du projet technique&nbsp;qui amènent à prendre pour fin ce qui n’est que moyen. Il est grand temps
      de reconnaître que l’outil est parvenu à imposer sa loi propre, même à ceux qui s’imaginent en être les
      maîtres</span><span class="span2">&nbsp;»</span><span class="span2">.</span>
    </p>
    <p class="para3">
      <span class="span2">Jeune polytechnicien ayant fait le choix de rompre avec la carrière d’ingénieur pour
      devenir</span> <span class="span2">philosophe, Jean-Pierre Dupuy est alors très proche d’Ivan Illich qu’il a
      côtoyé au Mexique. Les écrits d’Illich jouent en effet un rôle décisif dans la première moitié des années 1970.
      Ce sont eux qui amènent par exemple André Gorz vers l’écologie politique et permettent une alliance de la
      critique marxiste et écologiste autour de la contestation technocritique. Autour de penseurs marxistes
      hétérodoxes s’élabore en effet une critique radicale de l’organisation scientifique du travail et du contrôle de
      la technologie par le capital. Dans son recueil sur la</span> <span class="span6">Critique de la division du
      travail</span><span class="span2">, André Gorz constatait ainsi que «&nbsp;l’histoire de la technologie
      capitaliste peut-être lue dans l’ensemble comme l’histoire de la déqualification des agents directs de la
      production&nbsp;». La question de l’autonomie de l’individu, de sa liberté d’action dans un univers d’abstraction
      et de réseaux techniques englobant devient centrale. Elle est au cœur des nombreux «&nbsp;pamphlets&nbsp;» –
      comme il appelait lui-même ses ouvrages&nbsp;– publiés par Ivan Illich au début des années 1970. Illich était un
      ancien prêtre qui avait rompu avec l’Église dans les années 1950 avant de se consacrer à l’enseignement en créant
      en 1961, dans une petite ville au sud de Mexico, un centre de formation interculturelle. Par ses ouvrages alors
      célèbres et traduits dans de nombreuses langues, comme</span> <span class="span6">La
      Convivialité</span><span class="span2">,</span> <span class="span6">Énergie et équité,</span> <span class=
      "span6">Une société sans école</span> <span class="span2">ou encore</span> <span class="span6">Némésis
      médicale</span><span class="span2">, tous publiés dans la première moitié des années 1970, tous le fruit de
      recherches et de réflexions largement collectives, Illich élabore une critique radicale de la société
      industrielle sur-outillée. Pour lui, les techniques ont cessé d’être des facteurs d’autonomie et d’émancipation
      pour devenir des sources d’aliénation. L’une des originalités de son travail est qu’il se tourne vers le monde
      des services plutôt que celui de l’industrie. À travers l’étude de ces «&nbsp;méga-machines&nbsp;» que sont
      l’école, l’hôpital, le système des transports, il forge le concept de «&nbsp;contre-productivité&nbsp;». Au-delà
      d’un certain seuil, explique-t-il, les techniques et les grandes institutions modernes deviennent en effet
      contre-productives, c’est-à-dire qu’elles se retournent contre leur finalité initiale&nbsp;: l’école désapprend,
      la vitesse des transports fait perdre du temps, la médecine devient néfaste à la santé.</span>
    </p>
    <p class="para3">
      <span class="span2">C’est dans</span> <span class="span6">La Convivialité</span> <span class="span2">(en
      américain</span> <span class="span6">Tools for Conviviality</span><span class="span2">) qu’Illich expose de la
      façon la plus radicale et la plus globale sa critique de la société industrielle et technicienne. L’ouvrage sort
      en même temps aux États-Unis, en Grande-Bretagne et en France en 1973. Il était d’abord paru en plusieurs
      livraisons dans le journal</span> <span class="span6">Le Monde</span><span class="span6">&nbsp;;</span>
      <span class="span2">dans les années qui suivent il est traduit en danois, néerlandais, japonais, espagnol,
      allemand et italien. Dans ce livre, présenté comme un «&nbsp;tract&nbsp;» et un «&nbsp;outil&nbsp;» pour l’action
      et la réflexion, l’enjeu est de proposer à la fois une critique générale du «&nbsp;mode industriel de
      production&nbsp;», tout en offrant des ressources conceptuelles pour définir «&nbsp;d’autres modes de production
      post-industriels&nbsp;». Illich ne s’attaque pas à «&nbsp;la&nbsp;» technique de façon générale et abstraite,
      mais à certaines d’entre elles, produites par le capitalisme, et au «&nbsp;méga-outil&nbsp;» dont le
      fonctionnement échappe à l’utilisateur. Illich prend d’ailleurs bien soin de distinguer entre «&nbsp;deux espèces
      de techniques&nbsp;»&nbsp;: celles qu’il qualifie de «&nbsp;conviviales&nbsp;», qui accroissent le champ de
      l’autonomie, et celles,&nbsp;«&nbsp;hétéronomes&nbsp;», qui le restreignent ou le suppriment. Il propose d’opérer
      un retour aux «&nbsp;outils conviviaux&nbsp;», ceux qui acceptent plusieurs utilisations et peuvent être
      l’expression libre de l’utilisateur. Entérinant l’échec historique de la gauche à domestiquer la machine, Illich
      suggère de reconstruire le rapport à la technique sur de nouvelles bases&nbsp;:</span>
    </p>
    <p class="para24">
      <span class="span6">«&nbsp;</span><span class="span6">Cela fait une centaine d’années que nous essayons de faire
      travailler la machine pour l’homme et d’éduquer l’homme à servir la machine. On s’aperçoit maintenant que la
      machine ne «&nbsp;marche&nbsp;» pas, que l’homme ne saurait se conformer à ses exigences […] La</span>
      <span class="span6">dictature du prolétariat et la civilisation des loisirs sont deux variantes politiques de la
      même domination par un outillage industriel en constante expansion. L’échec de cette grande aventure fait
      conclure à la fausseté de l’hypothèse&nbsp;». En s’inscrivant sans</span> <span class="span6">ambiguïté</span>
      <span class="span6">dans la tradition du socialisme et de ses idéaux de justice, il conclut que «&nbsp;l’idéal
      proposé par la tradition socialiste ne se traduira dans la réalité que si l’on inverse les institutions régnantes
      et que si l’on substitue à l’outillage industriel des outils conviviaux</span><span class="span6">&nbsp;»
      (Illich, 1973, p. 26).</span>
    </p>
    <p class="para3">
      <span class="span2">Rompant avec 150 ans de représentation du phénomène technique forgé au début de l’âge
      industriel, identifiant les relations entre le changement technique et le progrès social et moral, les années
      1970 constituent un moment de réflexivité et de mise en cause importante des trajectoires techniques antérieures
      et d’intenses expérimentations pour initier d’autres chemins alternatifs. Certes, les querelles autour des
      machines n’ont rien d’inédit dans le débat intellectuel, elles existent depuis les débuts de l’âge industriel et
      ressurgissent à chaque moment de crise et de transformation du capitalisme industriel, que</span> <span class=
      "span2">ce</span> <span class="span2">soit dans les années 1830, 1890 ou 1930 (Jarrige, 2014). Mais l’importance
      des questions environnementales et écologiques marque indéniablement la spécificité des années 1970 qui voit
      l’émergence d’une alliance inédite entre une critique sociale cherchant à renouveler les grilles d’analyses
      marxistes et une critique environnementale mettant en cause l’empreinte matérielle et écologique des grands
      outils techniques de la modernité que sont l’automobile, le nucléaire ou l’aviation. Les années 1960 avaient en
      effet été marquées par le déferlement de grands projets techniques dans tous les domaines, par la construction
      massive d’autoroute</span><span class="span2">s</span><span class="span2">, les grands programmes d’exploration
      lunaire, la compétition mondiale autour des grands projets modernisateurs à l’époque de la guerre froide. En
      Amérique du Nord comme en Europe, la contestation des «&nbsp;technosciences&nbsp;» devient dès lors un thème
      fédérateur pour les mouvements sociaux&nbsp;des années 1970</span><span class="span2">&nbsp;:</span> <span class=
      "span2">les pacifistes dénoncent l’arsenal technologique gigantesque déployé par le «&nbsp;complexe
      militaro-industriel&nbsp;» au Vietnam,&nbsp;alors que les mouvements écologistes critiquent le déferlement des
      pesticides chimiques et leurs menaces pour l’environnement.</span> <span class="span2">À</span> <span class=
      "span2">la suite des expertises et alertes scientifiques des années 1960 – notamment les célèbres écrits de la
      biologiste Rachel Carson – le Congrès des</span> <span class="span2">É</span><span class="span2">tats-Unis
      interdit en 1969 l’usage du DDT en raison de ses effets sur la santé, contre l’avis des experts de
      l’administration. En 1971, il refuse le financement de l’avion supersonique pourtant considéré comme prioritaire
      par le gouvernement. Dans un contexte de profonde recomposition idéologique, la critique des techniques se
      développe, se complexifie, acquiert une nouvelle légitimité et une audience inédite, alors même qu’un nombre
      croissant d’objets envahit le quotidien de la «&nbsp;société de consommation&nbsp;»&nbsp;: fours à micro-ondes,
      couches jetables, télécommandes et distributeurs de billets apparaissent tous au cours des années 1970.</span>
    </p>
    <p class="para3">
      <span class="span2">C’est dans ce contexte que Jean-Pierre Dupuy lance en 1975 la collection
      «&nbsp;Techno-critique&nbsp;», qui publie une quinzaine de titres avant de disparaître en 1981. Cette aventure
      éditoriale joua un rôle important dans le débat intellectuel des années 1970 et participa d’un mouvement bien
      plus vaste, en Europe comme aux</span> <span class="span2">É</span><span class="span2">tats-Unis, de remise en
      cause du consensus moderniste antérieur.</span> <span class="span2">À</span> <span class="span2">travers la
      notion de «&nbsp;technocritique&nbsp;», il s’agissait de rejeter les débats trop binaires entre les supposées
      «&nbsp;technophobes&nbsp;» réactionnaires et les «&nbsp;technophiles&nbsp;» progressistes en affirmant que les
      techniques n’étaient pas neutre</span><span class="span2">s</span><span class="span2">. L’enjeu était de formuler
      une critique politique des techniques en montrant qu’il s’agit d’institutions sociales insérées dans des rapports
      de force sociopolitiques et des environnements</span> <span class="span2">physiques fragiles. S’émancipant des
      alternatives trompeuses en termes de refus ou d’acception des techniques, les technocritiques des années 1970
      participent d’une réflexion bien plus vaste sur les «&nbsp;technologies alternatives&nbsp;» alors promues par de
      nombreux ingénieurs et expérimentateurs à la recherche de trajectoires techniques à petites échelles,
      décentralisées, sobres en énergie. Contre l’idée que les techniques seraient neutres et que
      seul</span><span class="span2">s</span> <span class="span2">les usages en définiraient le sens, les théoriciens
      et promoteurs des technologies douces considéraient qu’il ne suffit pas d’intervenir par la fiscalité, le droit
      ou les prix pour réguler les changements, c’est le type même des technologies et des infrastructures matérielles
      utilisées qui devait être interrogé.</span>
    </p>
    <p class="para3">
      <span class="span2">Les deux premiers ouvrages publiés en 1975 dans la collection «&nbsp;Techno-critique&nbsp;»
      sont significativement ceux de René Dumont, célèbre agronome devenu candidat écologiste à l’élection
      présidentielle française en 1973 et figure de proue du mouvement écologiste –</span> <span class="span6">La
      croissance… de la famine&nbsp;!</span> <span class="span2">–, qui invitait à repenser l’agriculture&nbsp;; et
      celui d’Illich,</span> <span class="span6">Némésis médical</span><span class="span6">e</span><span class=
      "span2">, traduit par Jean-Pierre Dupuy et publié en 1975. Dans les années qui suivent, la collection s’étoffe
      d’ouvrages importants pour l’histoire de la pensée écologique et la construction d’une écologie politique
      contestataire et subversive. Cornelius Castoriadis et Daniel Cohn-Bendit y publient ainsi</span> <span class=
      "span6">De l’écologie à l’autonomie</span> <span class="span2">en 1981, où ils s’interrogent sur les actions à
      entreprendre face aux</span> <span class="span2">«&nbsp;</span><span class="span2">potentialités apocalyptiques
      de la technoscience</span><span class="span2">&nbsp;»</span><span class="span2">. Jean Robert dénonce en
      1980</span> <span class="span6">Le temps qu’on nous vole. Contre la société chronophage.</span> <span class=
      "span2">Plusieurs médecins s’en prennent au fonctionnement de l’hôpital et à</span> <span class=
      "span6">L’Intoxication vaccinale</span><span class="span2">. Le socioéconomiste Ingmar Granstedt publie quant à
      lui en 1980</span> <span class="span6">L’Impasse industrielle</span> <span class="span2">où il scrute les ravages
      technologiques sur le monde du travail et imagine divers scénarios pour diminuer le temps de travail et
      développer des activités productives vernaculaires.</span>
    </p>
    <p class="para3">
      <span class="span2">Parallèlement à ces écrits technocritiques, la décennie 1970 voit aussi la diffusion élargie
      et la vogue pour des auteurs ayant</span> <span class="span2">élaboré</span> <span class="span2">leurs réflexions
      bien avant, mais qui étaient restés relativement marginaux dans le champ intellectuel. C’est notamment le cas de
      l’américain Lewis Mumford qui publie à la fin des années 1960</span> <span class="span6">Le</span> <span class=
      "span6">Mythe de la machine</span><span class="span2">, vaste somme traduite en français dès 1973. Il y explore
      les transformations de la condition humaine et les raisons qui expliquent «&nbsp;l’abandon irrésistible de
      l’homme moderne à sa technologie, même au prix de sa santé, de sa sécurité physique, de son équilibre
      mental&nbsp;» (Mumford, 1973&nbsp;: vol. 1,&nbsp; 11). L’ouvrage connaît un grand succès car il paraît en phase
      avec les contestations radicales de l’autoritarisme bureaucratique et du gigantisme technologique qui suivent
      1968. Le «&nbsp;mythe de la machine&nbsp;» désigne l’illusion selon laquelle l’être humain serait d’abord</span>
      <span class="span6">Homo faber</span><span class="span2">, homme fabricant au moyen d’outils puis de machines.
      Contre cette thèse «&nbsp;sclérosante&nbsp;», Mumford suggère «&nbsp;que l’homme est surtout un animal créateur
      d’esprit, qui se maîtrise soi-même et se crée soi-même&nbsp;»&nbsp;; plutôt que la maîtrise de son environnement,
      le développement humain vise d’abord au développement de son organisme et de son organisation sociale. La thèse
      est ambitieuse puisqu’il s’agit purement et simplement de refonder «&nbsp;les représentations stéréotypées du
      développement humain&nbsp;» afin de sortir du fatalisme technologique. Dans son livre, Mumford analyse aussi le
      tragique qui accompagne le déploiement de la civilisation industrielle où les promesses de la technique moderne
      ont été trahies par ce qu’il nomme la «&nbsp;méga-machine&nbsp;» autoritaire. Dans la continuité de ses travaux
      des années 1960, il s’efforce de définir ce qu’il appelle «&nbsp;les deux technologies&nbsp;»&nbsp;: «&nbsp;l’une
      «&nbsp;démocratique&nbsp;» et dispersée, l’autre totalitaire et centralisée&nbsp;» (Mumford,
      1963)</span><span class="span2">&nbsp;:</span> <span class="span2">pour Mumford, la technique n’est pas pour
      autant devenue autonome et omnipotente. Il juge que les sociétés humaines pourraient reprendre le contrôle et
      diriger leurs</span> <span class="span2">trajectoires, en bref qu’elles continuent d’avoir le choix.</span>
    </p>
    <p class="para3">
      <span class="span2">Plus pessimiste et fataliste quant au devenir des sociétés techniciennes, il faut également
      mentionner le français Jacques Ellul qui devient une figure de premier plan du débat intellectuel au cours des
      années 1970, échangeant notamment avec</span> <span class="span2">Cornelius</span> <span class=
      "span2">Castoriadis ou Guy Debord. C’est d’ailleurs sous l’influence d’Ellul que Debord se tourne vers la
      question de la technique et de l’écologie politique après la publication de La</span> <span class="span6">Société
      du Spectacle</span> <span class="span2">en 1967. Dans les années 1970, Jacques Ellul publie beaucoup. Après 1968,
      il s’engage par exemple dans une vaste réflexion sur le phénomène des révolutions. Selon lui, elles sont
      désormais impossibles car le fétichisme de la marchandise exacerbée par la société technicienne fait passer
      l’idéal de liberté au second plan derrière la recherche du confort matériel. La société technicienne annihile la
      capacité révolutionnaire du prolétariat car</span> <span class="span2">«&nbsp;</span><span class="span2">la
      société n’est plus fonction du capital mais de la technique qui est puissamment intégratrice&nbsp;» (Ellul,
      1969&nbsp;: 29). Si la classe ouvrière existe toujours, elle ne peut plus être révolutionnaire comme au temps de
      Marx car le prolétariat a été absorbé par la société technicienne jusqu’à partager ses objectifs et ses
      aspirations. En 1977 il publie</span> <span class="span6">Le Système technicien</span><span class="span2">,
      deuxième volet de sa trilogie inaugurée dans les années 1950 avec son premier livre intitulé</span> <span class=
      "span6">La Technique, ou l’enjeu du siècle</span><span class="span2">. Il y propose une analyse très dense des
      liens entre «&nbsp;technique&nbsp;» et «&nbsp;société&nbsp;» et montre comment la première s’est désormais
      constituée en un système interdépendant et s’est imposée comme le facteur déterminant de l’évolution
      sociale&nbsp;; un système qui</span> <span class="span2">s’accroît</span> <span class="span2">sans cesse aux
      dépens de la démocratie comme des ressources naturelles. Même si cette affirmation de l’autonomie de la technique
      est largement repoussée et contestée, le thème s’installe au centre de nombreux débats et analyses. C’est
      d’ailleurs pour répondre aux apories de la société technicienne qu’Ellul s’engage dans le militantisme écologiste
      dans les années 1970, notamment contre la Mission interministérielle de la côte aquitaine qui tente</span>
      <span class="span2">de</span> <span class="span2">promouvoir de grands équipements pour stimuler l’aménagement et
      le développement du tourisme.</span>
    </p>
    <p class="para3">
      <span class="span2">Après une décennie de technocritiques intenses et de mise en cause de l’emprise
      technoscientifique sur le monde au nom de la liberté, de l’émancipation et de la préservation de la biosphère,
      les années 1980 sont marquées par un reflux. Les expérimentations en faveur des technologies alternatives
      échouent face aux choix politiques en faveur de la puissance, face aussi à l’influence croissante des grands
      lobbies industriels dans un contexte de compétition internationale exacerbée. La question des techniques tend à
      disparaître du champ politique alors même que de nouvelles utopies technologiques accompagnent le triomphe de
      l’informatique et de ses idéologies de la communication. Ces évolutions réactivent les anciens mythes du progrès.
      Les raisons pour lesquelles s’opérait la «&nbsp;technocritique&nbsp;» des années 1970 s’effacent alors que la
      nouvelle frontière informatique annonce la croissance et le plein emploi, la «&nbsp;dématérialisation&nbsp;»
      censée atténuer les destructions écologiques ou l’imaginaire des réseaux ouvrant la démocratie numérique. Au
      cours des années 1990-2000 pourtant, les promesses technologiques semblent à nouveau déçues et la technocritique
      semble ressurgir. Elle retrouve une indéniable légitimité, alors que les sciences du système terre et de la
      nature s’accordent de plus en plus pour voir dans notre planète un organisme appauvri par les activités
      industrielles et leur gigantisme technique, où les équilibres sont altérés et la faune et la flore partout en
      crise, où les catastrophes se multiplient de façon de plus en plus incontrôlable, préparant un effondrement
      social et environnemental désormais annoncé.</span>
    </p>
    <p class="para3">
      <span class="span2">Plus qu’une</span> <span class="span2">«&nbsp;</span><span class="span2">crise
      écologique&nbsp;» ou «&nbsp;environnementale&nbsp;», qui nécessiterait une bonne gestion de la</span>
      <span class="span2">part de décideurs enfin devenus conscients, l’idée que nous vivons une révolution de nature
      géologique impliquant de repenser en profondeur nos imaginaires, comme les attachements qui nous relient aux
      objets, aux autres et au monde, s’impose. C’est d’ailleurs en l’an 2000 qu’est apparue la notion d’anthropocène,
      censée caractériser la nouvelle ère géologique qui s’est ouverte avec l’entrée dans l’ère industrielle, ou que
      s’impose le «&nbsp;principe de précaution&nbsp;» censé institutionnaliser des politiques plus prudentes face aux
      risques technoscientifiques. L’ampleur des controverses autour des OGM constitue sans doute l’apogée de cette
      nouvelle phase technocritique intense. Depuis le début des années 2010 pourtant, l’imaginaire du progrès
      technique dans sa version la plus rudimentaire ne cesse d’être réactivé et de ressurgir, d’envahir les médias en
      marginalisant les discours critiques (Huesemann, 2011). La montée en puissance du transhumanisme, les nouvelles
      utopies de «&nbsp;l’accélération&nbsp;» et de la modernisation écologique, les idéologies numériques
      omniprésentes, les vastes projets de géoingénierie, tout annonce un monde toujours plus fasciné par la technique
      et ses possibilités. Stimulés par des États impuissants et des entreprises multinationales omniprésentes, les
      discours fatalistes affirmant qu’il n’y a pas d’autres chemins que la course en avant technoscientifique
      s’imposent un peu partout, au risque d’intensifier encore l’effondrement en cours.</span>
    </p>
    <p class="para3">
      &nbsp;
    </p>
    <p class="para3">
      <span class="span58">Bibliographie&nbsp;:</span>
    </p>
    <p class="para3">
      <span class="span2">BIAGINI, CARNINO G.,</span> <span class="span6">Les Luddites en France. Résistance à
      l’industrialisation et à l’informatisation</span><span class="span2">, Montreuil, L’échappée, 2010.</span>
    </p>
    <p class="para3">
      <span class="span2">ELLUL J.,</span> <span class="span6">De la révolution aux révoltes</span><span class=
      "span2">, Paris, La Table ronde, 2011 [1969].</span>
    </p>
    <p class="para3">
      <span class="span2">HUESEMANN M. et J.,</span> <span class="span6">Techno-Fix. Why Technology Won’t Save Us or
      the Environment</span><span class="span2">, New Society Publishers, Gabriola Island, 2011.</span>
    </p>
    <p class="para3">
      <span class="span2">ILLICH I.,</span> <span class="span6">La Convivialité</span><span class="span2">, Paris, Le
      Seuil, 1973.</span>
    </p>
    <p class="para3">
      <span class="span2">J</span><span class="span2">ARRIGE F.,</span> <span class="span6">Technocritique. Du refus
      des machines à la contestation des technosciences</span><span class="span2">, Paris, La Découverte, 2014.</span>
    </p>
    <p class="para3">
      <span class="span2">MATHIEU L.,</span> <span class="span6">Les Années 70, un âge d’or des
      luttes</span><span class="span6">&nbsp;?</span><span class="span2">, Textuel, coll.</span> <span class=
      "span2">«&nbsp;</span><span class="span2">Encyclopédie critique</span><span class=
      "span2">&nbsp;»</span><span class="span2">, 2010.</span>
    </p>
    <p class="para3">
      <span class="span2">MUMFORD L.,</span> <span class="span6">Pour une technologie démocratique</span><span class=
      "span2">, La Table ronde, 1963. Réédité dans la revue</span> <span class="span6">Agone</span><span class=
      "span2">. Consultable en ligne</span><span class="span2">&nbsp;:</span> <span class=
      "span2">http://revueagone.revues. org/1013.</span>
    </p>
    <p class="para3">
      <span class="span2">MUMFORD L.,</span> <span class="span6">Le Mythe de la machine</span><span class="span2">,
      t</span><span class="span6">. 1., La Technologie et le développement humain</span> <span class="span2">[1967],
      et</span> <span class="span6">vol. 2, Le Pentagone de la puissance</span> <span class="span2">[1970], Fayard,
      Paris, 1973.</span>
    </p>
    <p class="para3">
      <span class="span2">PESSIS C. (dir.),</span> <span class="span6">Survivre et vivre. Critique de la science,
      naissance de l’écologie</span><span class="span2">, Montreuil, L’échappée, 2013.</span>
    </p>
    <p class="para3">
      <span class="span2">PESSIS C., TOPÇU S. et BONNEUIL C.&nbsp;(dir.),</span> <span class="span6">Une autre histoire
      des</span> <span class="span6">«&nbsp;</span><span class="span6">Trente Glorieuses</span><span class=
      "span6">&nbsp;»</span><span class="span6">. Modernisation, contestations et pollutions dans la France
      d’après-guerre</span><span class="span2">, Paris, La Découverte, 2013.</span>
    </p>
    <p class="para3">
      &nbsp;
    </p>
    <p class="para33">
      <span class="span8">---------</span>
    </p>
    <p class="para34">
      <span class="span59">P</span><span class="span59">aru dans la revue en ligne</span> <span class="span60">La
      Pensée</span> <span class="span60">Écologique</span> <span class="span59">en octobre 2017</span>
    </p>
    <p class="para34">
      <span class=
      "span59">https://lapenseeecologique.com/jarrige-francois-techno-critique-et-ecologie-annees-1970/</span>
    </p>
    <aside epub:type="footnote" id="dataF1">
      <p class="para14">
        <span class="span9"><sup><a href="#calledF1">50</a></sup>&nbsp;</span><span class="span9">Sophie Joissains,
        Rapport n° 350 (2017-2018) fait au nom de la commission des lois sur le projet de loi relatif à la protection
        des données personnelles, 14 mars 2018.</span> <a href=
        "https://www.senat.fr/rap/l17-350/l17-350.html"><span class=
        "span18">https://www.senat.fr/rap/l17-350/l17-350.html</span></a>
      </p>
    </aside><br />
    <aside epub:type="footnote" id="dataF2">
      <p class="para32">
        <span class="span9"><sup><a href="#calledF2">51</a></sup>&nbsp;</span><span class="span9">Les algorithmes
        locaux de Parcoursup (ceux utilisés par les commissions de classement des vœux de chaque université) ne sont
        d’ailleurs qu’une feuille de calcul dont les pondérations sont laissées à l’appréciation de chaque
        commission.</span>
      </p>
    </aside><br />
    <aside epub:type="footnote" id="dataF3">
      <p class="para14">
        <span class="span9"><sup><a href="#calledF3">52</a></sup>&nbsp;</span><span class="span9">Sans entrer dans les
        débats de la doctrine administrativiste autour la notion d’acte administratif, notons simplement que cette
        définition n’est pas partagée pas tou·tes les juristes.</span>
      </p>
    </aside><br />
    <aside epub:type="footnote" id="dataF4">
      <p class="para14">
        <span class="span9"><sup><a href="#calledF4">53</a></sup>&nbsp;</span><span class="span9">Loi n° 2016-1321 du 7
        octobre 2016 pour une République numérique, article 4, créant l’article L. 311-3-1 du code des relations entre
        le public et l’administration sur les décisions administratives individuelles prises sur le fondement d’un
        traitement algorithmique.</span>
      </p>
    </aside><br />
    <aside epub:type="footnote" id="dataF5">
      <p class="para32">
        <span class="span9"><sup><a href="#calledF5">54</a></sup>&nbsp;</span><span class="span9">Notons déjà d’emblée
        que les appréciations ne peuvent pas, par une simple feuille de calcul, être évaluées : elles sont donc
        nécessairement mises de côté par l’algorithme et les commissions de classement ne s’en serviront alors que
        pour</span> <span class="span9">dé</span><span class="span9">partager deux éventuel·les candidat·es avec
        exactement le même rang.</span>
      </p>
    </aside><br />
    <aside epub:type="footnote" id="dataF6">
      <p class="para14">
        <span class="span9"><sup><a href="#calledF6">55</a></sup>&nbsp;</span><span class="span9">Loi n° 2015-912 du 24
        juillet 2015 relative au renseignement, article 15, créant l’article L. 851-2 du code de la sécurité
        intérieure.</span>
      </p>
    </aside><br />
    <aside epub:type="footnote" id="dataF7">
      <p class="para14">
        <span class="span9"><sup><a href="#calledF7">56</a></sup>&nbsp;</span><span class="span9">Ce qui, selon
        l’article R. 311-3-1-2 du même code, englobe, notamment,</span> <span class="span9">«&nbsp;</span><span class=
        "span10">les paramètres de traitement et, le cas échéant, leur pondération, appliqués à la situation de
        l’intéressé</span><span class="span10">&nbsp;»</span> <span class="span9">ainsi que</span> <span class=
        "span9">«&nbsp;</span><span class="span10">les opérations effectuées par le traitement</span><span class=
        "span10">&nbsp;»</span><span class="span9">.</span>
      </p>
    </aside><br />
    <aside epub:type="footnote" id="dataF8">
      <p class="para14">
        <span class="span9"><sup><a href="#calledF8">57</a></sup>&nbsp;</span><span class="span9">Cons. const., 12 juin
        2018,</span> <span class="span10">Loi relative à la protection des données personnelles</span><span class=
        "span9">, n° 2018-765 DC, point 71.</span>
      </p>
    </aside><br />
    <aside epub:type="footnote" id="dataF9">
      <p class="para14">
        <span class="span9"><sup><a href="#calledF9">58</a></sup>&nbsp;</span><span class="span9">Art. L. 300-2 du code
        des relations entre le public et l’administration.</span>
      </p>
    </aside><br />
    <aside epub:type="footnote" id="dataF10">
      <p class="para32">
        <span class="span9"><sup><a href="#calledF10">59</a></sup>&nbsp;</span><span class="span9">Art. L. 311-1 du
        code des relations entre le public et l’administration.</span>
      </p>
    </aside><br />
    <aside epub:type="footnote" id="dataF11">
      <p class="para3">
        <span class="span9"><sup><a href="#calledF11">60</a></sup>&nbsp;</span><span class="span9">Cour suprême du
        Wisconsin,</span> <span class="span10">State vs. Eric L. Loomis</span><span class="span9">, 13 juillet
        2016.</span>
      </p>
    </aside><br />
    <aside epub:type="footnote" id="dataF12">
      <p class="para13">
        <span class="span55"><sup><a href="#calledF12">61</a></sup>&nbsp;</span><span class="span55">En anglais, le
        titre du livre est un jeu de mot entre «&nbsp;Mass Destruction</span> <span class=
        "span55">Weapons</span><span class="span55">&nbsp;» (armes de destructions massives) et «&nbsp;Math
        destruction</span> <span class="span55">weapons</span><span class="span55">&nbsp;» (armes de destructions
        mathématiques)</span>
      </p>
    </aside><br />
    <aside epub:type="footnote" id="dataF13">
      <p class="para8">
        <sup><a href="#calledF13">62</a></sup><a href=
        "https://theshiftproject.org/wp-content/uploads/2018/11/Rapport-final-v8-WEB.pdf"><span class=
        "span18">https://theshiftproject.org/wp-content/uploads/2018/11/Rapport-final-v8-WEB.pdf</span></a>
      </p>
    </aside><br />
    <aside epub:type="footnote" id="dataF14">
      <p class="para8">
        <sup><a href="#calledF14">63</a></sup><a href=
        "https://theshiftproject.org/article/pour-une-sobriete-numerique-rapport-shift/"><span class=
        "span18">https://theshiftproject.org/article/pour-une-sobriete-numerique-rapport-shift/</span></a>
      </p>
    </aside><br />
  </body>
</html>
