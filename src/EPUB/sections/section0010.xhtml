<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type"/>
    <link href="../styles/stylesheet.css" rel="stylesheet" type="text/css"/>
    <title/>
  </head>
  <body xmlns:epub="http://www.idpf.org/2007/ops" class="body0">
  <p class="para14">
      <span class="span5">Les algorithmes, « armes de destruction mathématiques »</span>
    </p>
    <p class="para3">
       
    </p>
    <p class="para3">
      <span class="span53">La mathématicienne et « scientifique des données » Cathy O'Neil, ex-analyste à Wall Street
      et militante du mo</span><span class="span53">u</span><span class="span53">vement Occupy, a publié en 2018 son
      livre « Algorithmes. La bombe à retardement ». Elle y présente une analyse problématisée de</span> <span class="span53">l’</span><span class="span53">impact</span> <span class="span53">d’</span><span class="span53">une
      société qui livre de plus en plus de décisions sociales fondamentales à des algorithmes. Voici une courte
      synthèse de ses principaux arguments. </span>
    </p>
    <p class="para3">
      <span class="span2">Les algorithmes, de même que tout ce qui est associé à la science et à la technologie, ont
      tendance à être perçus comme un mécanisme objectif, neutre, extérieur aux complexités sociales. Or, argumente
      Cathy O'Neil, les algorithmes sont plutôt le reflet</span> <span class="span2">d’</span><span class="span2">opinions non-scientifiques des développeurs, qui contrôlent et prennent les décisions sur leur production
      finale. En particulier,</span> <span class="span2">c’</span><span class="span2">est le type de données à utiliser
      et la définition du résultat attendu qui, en</span> <span class="span2">soi</span><span class="span2">, est
      sensible aux biais sociaux et idéologiques de ces développeurs. </span>
    </p>
    <p class="para3">
      <span class="span2">Sans réflexion critique préalable, les algorithmes en arrivent à reproduire, voire amplifier,
      les inégalités sociales. Par exemple, si un algorithme doit déterminer quel·les candidat·es ont le plus de
      chance</span> <span class="span2">d’</span><span class="span2">être embauché·es à Fox News (pour reprendre
      l</span><span class="span2">’</span><span class="span2">exemple développé par la mathématicienne), il se basera
      sur les caractéristiques sociales des dirigeants historiques de la chaîne de télévision : hommes, blancs, de
      classes moyennes ou supérieur</span><span class="span2">e</span><span class="span2">s. Les femmes auraient
      beaucoup moins de probabilité</span> <span class="span2">d’</span><span class="span2">être sélectionnées
      par</span> <span class="span2">l’</span><span class="span2">algorithme car dans le passé</span> <span class="span2">elles</span> <span class="span2">n</span><span class="span2">’</span><span class="span2">avaient pas
      accès à ces postes</span><span class="span2"> :</span> <span class="span2">en un sens, le passé définit le futur.
      Ainsi, si on construit un algorithme à partir</span> <span class="span2">d’</span><span class="span2">une culture
      discriminatoire, les inégalités ne peuvent être que reproduites et amplifiées par les calculs
      automatisés. </span>
    </p>
    <p class="para3">
      <span class="span2">Selon cette auteure, les algorithmes sont des « armes de destructions
      mathématiques »</span><sup id="calledF12"><a epub:type="noteref" href="#dataF12">61</a></sup> <span class="span2">pour trois raisons.</span>
    </p>
    <p class="para3">
      <span class="span2">Il</span> <span class="span2">s’</span><span class="span2">agit</span> <span class="span2">d’</span><span class="span2">un système de notation qui prend des décisions graves, importantes, à fort
      impact sur la vie des personnes ;</span>
    </p>
    <p class="para3">
      <span class="span2">Leur fabrication est maintenue secrète, tout autant que la nature des données prises en
      compte et des définitions du résultat à atteindre ;</span>
    </p>
    <p class="para3">
      <span class="span2">Les algorithmes sont fondamentalement injustes, car ils creusent les inégalités
      sociales. </span>
    </p>
    <p class="para3">
      <span class="span2">L’</span><span class="span2">exemple paradigmatique de cela est</span> <span class="span2">l’</span><span class="span2">algorithme de prédiction de récidive utilisé par le système
      judicia</span><span class="span2">i</span><span class="span2">re états-unien. En obtenant un score élevé, une
      personne condamnée reçoit une peine de prison plus longue pour « éviter la récidive ». Or, les données utilisées
      présentent un biais raciste évident</span><span class="span2"> :</span> <span class="span2">le taux de
      criminalité du quartier de résidence (dans un pays géographiquement très ségrégué), si le père du détenu a fait
      de la prison,</span> <span class="span2">s’</span><span class="span2">il touche des prestations
      sociales</span><span class="span2">…</span> <span class="span2">Des éléments que la population afro-états-unienne
      a beaucoup plus de probabilité de rassembler. Les hommes noirs se retrouvent donc à écoper des peines de prison
      bien plus longues que les hommes blancs pour les mêmes délits ou crimes.</span> <span class="span2">Cet
      algorithme, mis en place à l'origine pour contrebalancer le racisme notoire de certain·es juges états-unien·nes
      grâce à des mesures « objectives », finit par inscrire en son sein même le racisme</span> <span class="span2">qu’</span><span class="span2">il était censé combattre –voire pire, car la croyance en</span>
      <span class="span2">l’</span><span class="span2">objectivité de</span> <span class="span2">l’</span><span class="span2">algorithme rend plus invisible</span><span class="span2">s</span> <span class="span2">les dynamiques
      racistes à</span> <span class="span2">l’œuvre.</span><span class="span2"> </span>
    </p>
    <p class="para3">
      <span class="span2">Le problème réside donc</span> <span class="span2">d’</span><span class="span2">un côté, en
      cette fausse impression de la neutralité des algorithmes, et de</span> <span class="span2">l’</span><span class="span2">autre, en</span> <span class="span2">l’</span><span class="span2">absence de conscience sociale des
      développeurs informatiques qui ne se sentent pas responsable</span><span class="span2">s</span> <span class="span2">de leur production technologique sur le plan éthique. Aucun garde-fou ne leur est</span> <span class="span2">d’</span><span class="span2">ailleurs opposé, car</span> <span class="span2">l’</span><span class="span2">idée</span> <span class="span2">qu’</span><span class="span2">ils « savent ce</span> <span class="span2">qu’</span><span class="span2">ils font car ils ont un doctorat » est largement répandue. Les algorithmes
      deviennent ainsi un mécanisme pour éluder les responsabilités personnelles et collectives face aux erreurs
      commises et aux injustices sociales. </span>
    </p>
    <p class="para3">
      <span class="span2">Il est donc urgent, rappelle O'Neil,</span> <span class="span2">d’</span><span class="span2">exiger collectivement un droit de regard citoyen sur la fabrication et</span> <span class="span2">l’</span><span class="span2">utilisation des algorithmes</span><span class="span2"> ;</span> <span class="span2">qu’</span><span class="span2">il soit possible de pousser les responsables techniques et politiques à
      rendre des comptes sur ces utilisations</span><span class="span2"> ;</span> <span class="span2">et que soient mis
      en place des mécanismes</span> <span class="span2">d’</span><span class="span2">appels de décisions prises par
      algorithmes. </span>
    </p>
    <p class="para3">
       
    </p>
    <p class="para3">
       
    </p>
    <p class="para3">
       
    </p>
    <p class="para3">
       
    </p>
    <p class="para3">
       
    </p>
    <p class="para3">
       
    </p>
    <p class="para3">
       
    </p>
    <p class="para13">
      <span class="span17">P</span><span class="span17">ARTIE II</span> <span class="span17">: D</span><span class="span17">ES ENJEUX ENVIRONNEMENTAUX</span>
    </p>
    <aside epub:type="footnote" id="dataF12">
      <p class="para14">
        <span class="span62"><sup><a href="#calledF12">61</a></sup> </span><span class="span62">En anglais, le titre du
        livre est un jeu de mot entre « Mass</span> <span class="span62">d</span><span class="span62">estruction</span>
        <span class="span62">weapons</span><span class="span62"> » (armes de destructions massives) et « Math
        destruction</span> <span class="span62">weapons</span><span class="span62"> » (armes de destructions
        mathématiques)</span>
      </p>
    </aside></body>
</html>